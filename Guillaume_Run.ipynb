{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca42fd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finish installing and importing all necessary libraries!\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.getcwd() + \"/deep-hedging\")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import QuantLib as ql\n",
    "import tensorflow as tf\n",
    "from scipy.stats import norm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, \\\n",
    "                                            ReduceLROnPlateau\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stochastic_processes import BlackScholesProcess\n",
    "from instruments import EuropeanCall\n",
    "from deep_hedging import Deep_Hedging_Model_LSTM,Deep_Hedging_Model_Transformer, Delta_SubModel\n",
    "from loss_metrics import Entropy\n",
    "from utilities import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "clear_output()\n",
    "print(\"\\nFinish installing and importing all necessary libraries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b0f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title <font color='Blue'>**User Inputs**</font>\n",
    "\n",
    "# Geometric Brownian Motion.\n",
    "N = 30 # Number of time steps (in days)\n",
    "\n",
    "S0 = 100.0 # Stock price at time = 0\n",
    "sigma = 0.2 # Implied volatility\n",
    "risk_free = 0.0 # Risk-free rate\n",
    "dividend = 0.0 # Continuous dividend yield\n",
    "\n",
    "Ktrain = 1*(10**5) # Size of training sample.\n",
    "Ktest_ratio = 0.2 # Fraction of training sample as testing sample.\n",
    "initial_wealth = 0.0\n",
    "# European call option (short).\n",
    "strike = S0\n",
    "payoff_func = lambda x: -np.maximum(x - strike, 0.0)\n",
    "calculation_date = ql.Date.todaysDate()\n",
    "maturity_date = ql.Date.todaysDate() + N\n",
    "\n",
    "# Day convention.\n",
    "day_count = ql.Actual365Fixed() # Actual/Actual (ISDA)\n",
    "\n",
    "# Proportional transaction cost.\n",
    "epsilon = 0.0\n",
    "\n",
    "# Information set (in string)\n",
    "# Choose from: S, log_S, normalized_log_S (by S0)\n",
    "information_set = \"normalized_log_S\"\n",
    "\n",
    "# Loss function\n",
    "# loss_type = \"CVaR\" (Expected Shortfall) -> loss_param = alpha \n",
    "# loss_type = \"Entropy\" -> loss_param = lambda \n",
    "\n",
    "loss_type = \"Entropy\"\n",
    "loss_param = 1.0\n",
    "\n",
    "# Neural network (NN) structure\n",
    "m = 15 # Number of neurons in each hidden layer.\n",
    "d = 1 # Number of hidden layers (Note including input nor output layer)         \n",
    "maxT = 5\n",
    "# Neural network training parameters\n",
    "lr = 1e-2 # Learning rate\n",
    "batch_size=256 # Batch size\n",
    "epochs=50 # Number of epochs\n",
    "\n",
    "# Other parameters\n",
    "use_batch_norm = False\n",
    "kernel_initializer = \"he_uniform\"\n",
    "\n",
    "activation_dense = \"leaky_relu\"\n",
    "activation_output = \"sigmoid\"\n",
    "final_period_cost = False\n",
    "\n",
    "delta_constraint = (0.0, 1.0)\n",
    "share_stretegy_across_time = False\n",
    "cost_structure = \"constant\"\n",
    "\n",
    "# Other control flags for development purpose.\n",
    "mc_simulator = \"Numpy\" # \"QuantLib\" or \"Numpy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaef4cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "s0 = 100.0\n",
      "sigma = 0.2\n",
      "risk_free = 0.0\n",
      "\n",
      "Number of time steps = 30\n",
      "Length of each time step = 1/365\n",
      "\n",
      "Simulation Done!\n"
     ]
    }
   ],
   "source": [
    "seed = 0 # Random seed. Change to have deterministic outcome.\n",
    "\n",
    "# Total obs = Training + Testing\n",
    "nobs = int(Ktrain*(1+Ktest_ratio)) \n",
    "\t\t\n",
    "# Length of one time-step (as fraction of a year).\n",
    "dt = day_count.yearFraction(calculation_date,calculation_date + 1) \n",
    "maturity = N*dt # Maturities (in the unit of a year)\n",
    "\n",
    "#S0 is init stock price, sigma = Volatility, risk_free = ?, ?,time Day convention\n",
    "stochastic_process = BlackScholesProcess(s0 = S0, sigma = sigma, risk_free = risk_free, \\\n",
    "                        dividend = dividend, day_count = day_count, seed=seed)\n",
    "\n",
    "S = stochastic_process.gen_path(maturity, N, nobs)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "print(\"\\n\\ns0 = \" + str(S0))\n",
    "print(\"sigma = \" + str(sigma))\n",
    "print(\"risk_free = \" + str(risk_free) + \"\\n\")\n",
    "print(\"Number of time steps = \" + str(N))\n",
    "print(\"Length of each time step = \" + \"1/365\\n\")\n",
    "print(\"Simulation Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ed387b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABQAAAAPACAYAAABq3NR5AAAgAElEQVR4nOzdeZBd5Xkn4E4VxdSYzCRTqampQnYJbAMyYDKyhZPgiW3GieM4tgkTmziLw9jYEBPHGWwnWkACi10CYcxuAmIza4wBtbq10NpRo5aQhIQQ2vd9b6nV673v/OGow9FpSd1Sd3/d9z5P1fmHe+6977n39qt6f5xzvooAAAAAAEpWReoCAAAAAICeIwAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAEAAAAgBImAAQAAACAEiYABAAAAIASJgAkicbGxqirq4u6urpYt25dbNq0yWaz2Ww2m81ms9lsNls3b+vWrWufvxsbG1PHASQiACSJurq6qKiosNlsNpvNZrPZbDabzdZLW11dXeo4gEQEgCQhALTZbDabzWaz2Ww2m613NwFg+RIAksS6desyDSj1KdE2m81ms9lsNpvNZrOV4vb+E3DWrVuXOg4gEQEgSWzatKm9AW3atCl1OQAAAFCSzN9ECABJRAMCAACAnmf+JkIASCIaEAAAAPQ88zcRAkAS0YAAAACg55m/iRAAkogGBAAAAD3P/E2EAJBENCAAAADoeeZvIgSAJKIBAQAAQM8zfxMhACQRDQgAAAB6nvmbCAEgiWhAAAAA0PPM30QIAElEAwIAAICeZ/4mQgBIIhoQAAAA9DzzNxECQBLRgAAAAKDnmb+JEACSiAYEAAAAPc/8TYQAkEQ0IAAAAOh55m8iBIAkogEBAABAzzN/EyEAJBENCAAAAHqe+ZsIASCJaEAAAADQ88zfRAgASUQDAgAAgJ5n/iZCAEgiGhAAAAD0PPM3EQJAEtGAAAAAoOeZv4kQAJKIBgQAAAA9z/xNhACQRDQgAAAA6HnmbyIEgCSiAQEAAEDPM38TIQAkEQ0IAAAAep75mwgBYK/asWNHTJgwIUaOHBlf/OIX43d+53fa/wivvPLKLr9edXV1XH755TFgwIA4/fTTY8CAAXH55ZdHdXX1CZ+7YcOGePDBB+OKK66Ic889Nz7wgQ/Ef/pP/ykGDBgQX/3qV+PZZ5+N1tbWkzjKztGAAAAAoOeZv4kQAPaqI39wHW1dCQCLxWJcffXVx329q6++OorFYofPHzlyZPzGb/zGcZ9fUVERQ4YMiQ0bNnTT0WdpQAAAANDzzN9ECAB71fvDtQ996EPxhS984aQCwBEjRrQ/b/DgwfHcc89FXV1dPPfcczF48OD2x66//voOn3/VVVdFRUVFnHHGGfG3f/u3MX78+JgzZ04sWLAgnn766bj44ovbX+Occ86JgwcPdtMn8B80IAAAAOh55m8iBIC9atSoUTFhwoTYvn17RESsW7euywHgqlWr4rTTTms/Q+/w4cOZxxsaGmLIkCFRUVERp512WqxevTr3Gv/yL/8Sd955Z9TX13f4Hm1tbXHFFVe01zZ69OiuHWgnaEAAAADQ88zfRAgAkzqZAPDaa69tf05tbW2H+9TW1rbv8/3vf/+katu9e3ecfvrpUVFRERdddNFJvcbxaEAAAADQ88zfRAgAk+pqAFgsFmPAgAFRUVERgwYNOu6+5513XlRUVMQHP/jBY94L8ESOnEl4xhlnnNTzj0cD6h92HGiMpZv3R2tbIXUpAAAAnATzNxECwKS6GgCuWbOmff9rrrnmuPu+f5GQtWvXnlR9H//4x6OioiL+y3/5Lyf1/OPRgPq+yre3xlnDKmPg0Mr4wzunxcsLN0Vb4eTCZAAAANIwfxMhAEyqqwFgZWVl+/733HPPcfcdN25c+74TJ07scm07duxov9fgxRdf3OXnn4gG1LcdaGyJi26aHAOHVma2Px43I6qXbj3ps0oBAADoXeZvIgSASXU1AHzooYfa93/ppZeOu+9LL73Uvu/DDz/c5dp+/OMftz9/7NixXX7+pk2bjrvV1dVpQH3Y3VNW5MK/929fuW92zFixUxAIAADQxwkAiRAAJtXVAHDMmDHt+1dXVx9336qqqvZ977rrri7V9eabb7af/ffBD34wGhoauvT8iGh/785sGlDfsudQc1wwatJxA8Aj29cfnht16/akLhkAAIBjEAASIQBMqqsB4OjRo9v3r6mpOe6+NTU17fvefPPNna5p+/bt8cEPfjAqKiriN37jN074PsciAOy/bpv4bibkO2vYry/9PV4Q+HePzYslm/anLh0AAICjCACJEAAm1dfOAKyvr49PfvKT7c+7/fbbO/W8jrgEuH/acaAxzruhKhPu/dNzC6NQKMZri7fEpWOnHzcI/PunF8TK7fWpDwMAAIB/JwAkQgCYVF+6B2BjY2Nceuml7c/54Q9/2NnDOCkaUN808pWlmUDvw8Mnxrpdh9ofb20rxAvzN8Ylt9ccMwQ8e1hlXPf8otiwu+uXjgMAANC9zN9ECACT6moAOGHChB5ZBbi1tTW+8pWvtO//ne98pyuHcVI0oL5n456G+OiIiZkwb9gv3+5w36bWtnjijXXxyZunHjMI/MjwiTHi5SWxbX9jLx8JAAAAR5i/iRAAJtXVAHDNmjXt+19zzTXH3ffqq69u33ft2rXH3K9QKMQ3vvGN9n3/8i//MgqFQlcPpcs0oL7nxy8uzgR454yoii37Dh/3OQ3NrfHg9NVx0U2TjxkEnnt9VdxSuSz2HGrupSMBAADgCPM3EQLApLoaABaLxTjzzDOjoqIiBg0adNx9Bw0aFBUVFTFgwIAoFovH3O873/lOew1f/vKXo6WlpauHcVI0oL5l9c6DcfawbHB302vvdPr5Bxpb4u4pK+L8kdXHDALPH1kdd09+Lw409s5vDAAAAPM3vyYATKirAWBExPe+973259TW1na4T21tbfs+11577TFf67rrrmvf7/Of/3w0NTWdzGGcFA2ob/mHX7yVCesG3VAdO+u7/nvYfbApbqlcFudeX3XMIPCimybHg9NXR0Nzaw8cCQAAAO9n/iZCAJjUyQSAK1asiNNOOy0qKipiyJAhcfhw9hLNw4cPx5AhQ6KioiJOO+20WLlyZYevc+ONN7a/9yWXXBKHDh3qcL+eogH1Hcu2HMiFdHdWLz+l19y2vzFGvLwkPjJ84jGDwE/ePDXGz1kbTa1t3XQkAAAAHM38TYQAsFfNnj07xo8f376NHTu2/Y/w05/+dOax8ePHH/N1hg0b1v68wYMHx/PPPx/z58+P559/PgYPHtz+2PDhwzt8/s9+9rP2fQYMGBBz5syJpUuXHnfr7kuDNaC+46on6jLB3IU3Tor9Dd3zfW/Y3RDXvbAozhrWcQg4cGhlXHJ7TbxQtzFa23r+3pMAAADlxvxNhACwV1155ZXtf3Sd2Y6lUCjEt7/97eM+96qrrjrmYh6f/exnu1RHRUVFrFu3rls/Cw2ob1i4YW8ukPvZ6x2fNXoqVm6vj79/esExQ8CBQyvj0rHT47XFW6JQOPY9KwEAAOga8zcRAsBe1V0B4BETJ06Myy67LM4888w4/fTT48wzz4zLLrssqqqqjvs8ASBH/M2jb2ZCuMGjp8TBpp67N9+STfvj7x6bd9wg8Is/nRVTl20/7uI1AAAAdI75mwgBIIloQOnNXb07F779fOaaXnnveWv3xNcfmnvcIPDPH5gTb2/a1yv1AAAAlCrzNxECQBLRgNIqFovxfx58IxO4ferWqdHY0nsLchSLxZixYmd8+WezjxkCnnt9VWzdf/jELwad0FYoxqod9XG42cIzAACUD/M3EQJAEtGA0pq2fEcubHuqdn2SWorFYlQv3Rp/dPeMDkPAR2auTlIXpWXVjvr4/L//xn7v1tdj1Y761CUBAECvMH8TIQAkEQ0onUKhGF+6d1YmZPv0HTXR3Jp2Fd62QjFeXrgpPn1HTaa2bzxSm7Qu+r8F6/fERTdNzvyuvnTvLCtPAwBQFszfRAgASUQDSmfikq25s+xeWtB3voPJ72zL1PbREROjvrEldVn0U1OWbY9zr6/q8OzSh2c4uxQAgNJn/iZCAEgiGlAabYVi+2WQR7b/fdf0aCv0nRV3DzW1xkdHTMzUWL10W+qy6Ieem7chzh527IVmzr2+KtbvPpS6TAAA6FHmbyIEgCSiAaXxbws25UKQyre3pi4r528efTNT49B/ezt1SfQjxWIx7n195XFXmT6y/fWjtVEs9p0AHAAAupv5mwgBIIloQL2vubUQ/+vO7P31/vSns6LQh87+O+LRWWtyKxQLaeiMtkIxRry8pMOw78cvLo7rf5V/rC9dAg8AAN3N/E2EAJBENKDe98yb63PBR83y7anL6tDqnQdztS7bciB1WfRxjS1tcfVT8zsM/8ZOei+KxWIcbGqNP7jt9cxjv/uTybHrYFPq8gEAoEeYv4kQAJKIBtS7Glva4vduzYYef/7AnD57Vl2xWIw/vHNapt77p61KXRZ92P6Glvj6Q3Nzwd9ZwyrjybnrMvu+/u723H4/eG5hmsIBAKCHmb+JEACSiAbUu46+pHbg0Mp4Y9Wu1GUd18hXlmbq/dpDb6QuiT5q6/7D8YVxM3O/8XNGVMXEJR3f4/LaX7yV23/aezt6uXIAAOh55m8iBIAkogH1nkNNrfGJ0VMyQcdf/bw2dVknNG35jkzNHx4+MfY3tKQuiz5m5fb63CW9A4dWxoWjJsXc1buP+bwd9Y3x8RsnZZ5zye01caiptRerBwCAnmf+JkIASCIaUO+5rya/GupbG/amLuuEDje3xbnXV2XqnvD2ltRl0YcsWL8nLrppcu73ffEtU+PdrSe+Z+TzdRtyzx09YVkvVA4AAL3H/E2EAJBENKDesb+hJS486iynb4+vS11Wp135+LxM7T98YXHqkugjpizbnguIBw6tjEvvmh6b9jZ06jWKxWL85SPZ+waePawyFm/c18PVAwBA7zF/EyEAJBENqHeMmbQ8F5C8s2V/6rI67Yk31mVq/+TNU6JQ6JsLl9B7npu3Ic4ell/p97L758SeQ81deq21uw7FOUcFiV/86axoaSv0UPUAANC7zN9ECABJRAPqebsONsXHRlZngo1rf/FW6rK6ZMPuhlzI8/YmZ2eVq2KxGPe+nr+kfeDQyvjW+LpoaD65+/fdP21V7vUenL66m6sHAIA0zN9ECABJRAPqeT95bVnu0sZVOw6mLqvLLr1reuY4fjp1ZeqSSKCtUIwRLy/pMPz78YuLT+mMvZa2QvzJPdlVhM+9virW7TrUjUcAAABpmL+JEACSiAbUs7buP5y7rPFHL/bP++cdHWT++QNzUpdEL2tsaYurn5rfYfg3dtJ7USye+mXhCzfsjbOOuqz4rx+t7ZbXBgCAlMzfRAgASUQD6lnDjzpT6qMjJsbGPZ1bGKGvmbVyZ+ZYzhpW2eX7vNF/7W9oia8/NDcX/J01rDKenLuuW9/rxlffyb3Pi/M3dut7AABAbzN/EyEAJBENqOds2N0QHxk+MRNiXP+rJanLOmlNrW0x6IbsvQx/tXBz6rLoBVv3H44/HjcjF8qdM6IqJi7Z2u3vd7CpNf7gttcz7/W7P5kcuw42dft7AQBAbzF/EyEAJBENqOdc9/yi3L3Mth9oTF3WKbnqiezlnz94bmHqkuhhK7fX58K4gUMr48JRk2Lu6t099r41y7fn3vMfn/V7AwCg/zJ/EyEAJBENqGes3F6fu4/ZLZXLUpd1yp55c33urKy2gnuzlar56/bERTdNzgVxF98yNd7deqDH3/8ffvFW7r2nvbejx98XAAB6gvmbCAEgiWhAPePvn16QCS3OH1ldEvfL27zvcC6QWbB+b+qy6AFTlm2Pc49awGbg0Mq49K7psWlv79zHcmd9Uy6AvOT2mjjU1Nor7w8AAN3J/E2EAJBENKDut3Tz/lxocvfk91KX1W2OvhfcXSV0bPzas/M2xNlHncF6ZOXnvb0cZL9QtzFXx09e6/9n0wIAUH7M30QIAElEA+p+Vz4+LxNWXHTT5DjQ2JK6rG5z28R3M8f35Z/NTl0S3aRYLMZPp67MBW4Dh1bGt8bXRUNz7595VywW4xuP1GZqOXtYZSzeuK/XawEAgFNh/iZCAEgiGlD3mr9uTy44eWD6qtRldau5q3fnjnFHff9e3ISItkIxRry8pMPw759fWhytbYVkta3ddSjOOepy5D+5Z2a0JKwJAAC6yvxNhACQRDSg7lMsFuOKh+dmQopP3jw1yVlTPamlrRAXjJqUOc4X529MXRanoLGlLb775PwOw7+xk96LYjH9Qi/3T1tV8uE6AAClzfxNhACQRDSg7jN75a5cQPH4nLWpy+oRRy9ycu0zb6UuiZO0v6ElvvbQG7nf7lnDKuPJuetSl9eupa0Qf3LPzEyN515fFet2HUpdGgAAdIr5mwgBIIloQN2jWCzGV++fkwknfv+216OxpS11aT3i6IUZLrxxkssx+6Gt+w/nFnUZOLQyzhlRFROXbE1dXs6ijfvirKMWJ/mrn9f2iTMUAQDgRMzfRAgASUQD6h5Tlm3PhSjPztuQuqwes/1AY+5431yzO3VZdMGC9Xvj9297Pfc9XjhqUsxd3Xe/y5teeydX8wsuQQcAoB8wfxMhACQRDejUFQrF3KWJnxkzreTPiPvTn87KHPMd1ctTl0QnFArFeHD66vjw8Im5IO3iW6bGu1sPpC7xuA41tcYlt9fkVtreWd+UujQAADgu8zcRAkAS0YBO3auLt+SClF8t3Jy6rB43ZtLy3Kqs9G27DjbFNx+b1+FiH5feNT027W1IXWKnTFu+I1f/P/zCfSgBAOjbzN9ECABJRAM6Na1thbh07PRMEPHH42ZEW6H070k2f92eXAizdf/h1GVxDG+s3hUX3zK1w/Dviofnxp5DzalL7JLvP7swdxw1y7enLgsAAI7J/E2EAJBENKBTc/RiGAOHVkb10m2py+oVrW2FuOimyWVz38P+qq1QjLunrMgtnnFkpd9xU1b0y8B6Z31T7vf3B7e9HgebWlOXBgAAHTJ/EyEAJBEN6OQ1tbbl7kX2lftml9WKpEefhfXdJ+enLon32ba/Ma54eG6HZ/1dfMvUeGP1rtQlnpIX5ucD+BtffSd1WQAA0CHzNxECQBLRgE7eE2+sy4UPM1bsTF1Wr/rlW5syx3/+yOpoam1LXRYRMe29HTF49JQOw79vPjYvdh3s/4tmFIvF+Kuf1+bOaly4YW/q0gAAIMf8TYQAkEQ0oJNzuLkthhx1P7WvPzS3rM7+i/j1ohJHh0tzVvXvs8r6u5a2Qtw28d0Og78PD58YD81YHYV+eMnvsazbdSjOvb4qtyBNqa/CDQBA/2P+JkIASCIa0Ml5eMbqXLjy5prdqctK4qv3zc58DrdULktdUtnauKchLrt/Tofh3yW318SC9aV5ZtwD01fljvf+aatSlwUAABnmbyIEgCSiAXVdfWNL/O5PsosP/O2/vpm6rGTGTVmR+Sw+f/eM1CWVpeqlW+PCGyd1GP5998n5sa+hf63y2xUtbYX44k9nZY75nOurYs3Og6lLAwCAduZvIgSAJKIBdd09U1fkApbFG/elLiuZRRv35T6PjXsaUpdVNhpb2mLkK0s7DP7OGVEV4+esLYtL0xdv3BdnH7XS8V8+Un6X5QMA0HeZv4kQAJKIBtQ1ew81xwWjJuXOripnhUIxPnHUYhNPzV2XuqyysGbnwfjTo858O7J9dsy0WLp5f+oSe9VPXluW+xyer9uQuiwAAIgI8ze/JgAkCQ2oa26ryi6ucNawynhvW33qspK77vlFmc/lW+PrUpdU8n61cHN8bGR1h+HfPz67MA42taYusdcdamqNS26vyXwWH79xUuyob0xdGgAAmL+JCAEgiWhAnbfjQGOcd0N2tdEfPLcwdVl9wquLt2Q+l/NuqIrGlrbUZZWkhubW+PGLizsM/s67oSqer9tQ1pe9TntvR+5zufYXb6UuCwAAzN9EhACQRDSgzht11H3WPjx8YqzbdSh1WX3Cvobm3P3XZqzYmbqskvPetvr4/N0zOgz//ujuGbFiu7NRIyL+8dmFuc/n9Xe3py4LAIAyZ/4mQgBIIhpQ52zc0xAfHTExEygM/be3U5fVp/yfB9/IfD43vvpO6pJKRrFYjGfnbYhzr6/qMPwb+m9vx+FmZ1wesetgU26l7t+/7fWyvCwaAIC+w/xNhACQRDSgzvl/R93j7pwRVbF53+HUZfUp99WszC1Cwamrb2yJ73dwRtvAoZVx/sjqeGXR5tQl9kkvzt+Y+7x6M5QuFIqx40BjLNq4L6qWbI1fvLkhFpXxauEAAJi/+TUBIEloQCf27tYDcdZRl7eOnrAsdVl9ztLN+3OBy1qXSJ+SJZv2x2fGTOsw/PvSvbN8vsdRLBbjrx+tzS3a89aGvd3y2nsPNcc7W/bH1GXb48m56+L2quXxg+cWxtcfmhufvqMmd8Zw+wrZteu74egAAOiPzN9ECABJRAM6sW+Pr8sM8BeMmhR7DjWnLqvPKRaLcfEtUzOf1WOz16Yuq18qFovx2Oy1xwyRbnz1nWhqdcnviazbdSh32fQXxs2M5tbCcZ9X39gSK7bXx/T3dsSz8zbE3ZPfix+9uDj++tHauHTs9NxiQF3ZPjpiYizZtL+XPgEAAPoS8zcRAkAS0YCOr27dntwAf+/rK1OX1Wf980vZ1Wn/9l/fTF1Sv7OvoTmuemJ+h+HRx2+cFJPe2Za6xH7lwemrc5/jHdXL441Vu+KlBZviZ6+vjGG/fDv+7rF58cfjZsSFoyaddLjX2e2zY6a5HyEAQBkyfxMhACQRDejYisVi/MVRC1t8YvSUOGRwP6aJS7bm7pXY0Ozz6qz56/bEH9z2eoeh0eUPzIlNextSl9jvtLQV4os/ndXjod6xto8MnxifGD0l999/+MLi1B8NAAC9zPxNhACQRDSgY3v93e25oX38HJe0Hs+Bxpb48PDsZauvv7s9dVl9XqFQjPunrcp9dke226uWR0vb8S9b5dje3rQvzh7W/eHeWcMq41O3To3L7p8T33tmQYyesCwenbUmJi7ZGgs37I3tBxqjrVCMlrZCfPX+Obnn/2qhBVwAAMqJ+ZsIASCJaEAdaysU4wvjZmaG9U/fUXPCe4cRccXDczOf2/W/WpK6pD6tobk1/u6xeR0GTJ8YPSWmv7cjdYklYfSEZV0O+AaPnhJfundWXPXE/Bj5ytJ4cPrqeGXR5qhbtyc27W3oUii7YXdDXHDU5cUXjJoU63dbyAUAoFyYv4kQAJKIBtSxX761KRcGvLzQ59MZD83I3nPtkttrolgspi6rz/rhC4s7DJ++8UhtbD/QmLq8knG4uS2zoM+FoybFF8bNjCsfnxfDfrkkfvb6ynhpwaZ4Y9WuWLvrUDS2dP8iK68s2pz7nr9632z/YwEAoEyYv4kQAJKIBpTX1NoWl9xekxnS/+SemVEoCLE6471t9bmQY+X2+tRl9UmT3tmW+6zOHlYZP526Mtr83nrE/sMtUd/Ykuz9f/RiPvC9vWp5snoAAOg95m8iBIAkogHlPT5nbW5Ar1nuPnadVSwWcwtZPDJzdeqy+pxdB5tyi0NcOGpS1K7Znbo0etChptb43NjpuR4za+XO1KUBANDDzN9ECABJRAPKOtjUmgtlvvbQGy5h7aLhLy/JXc7KfygWi/GdJ+fnQqCXFvgbLAdLN++Pj47ILvgy5JapsetgU+rSAADoQeZvIgSAJKIBZd0zdUUulJm/bk/qsvqdyUdd2vrREROTXnbZ17y0IH+Pye8+OV/QXEYenbUm9xu48vF5bjUAAFDCzN9ECABJRAP6D7sPNsX5I6szA/lVT9SlLqtfOtTUmjvDqXrpttRl9Qmb9jbEhUetBvuJ0VOc/VVmCoViXPl4fvXnf529NnVpAAD0EPM3EQJAEgj79YcAACAASURBVNGA/sNNr72TGcTPGlYZ722zeMXJ+ptH38x8nkP/7e3UJSVXKBTjG4/U5kKfye8IR8vRroNNMeSWqbmzZZdu3p+6NAAAeoD5mwgBIIloQL+2cU9DnDOiKjOIX/fCotRl9WtHX+L4qVunlv0lrh0tMPOjFxenLouEZq/cFWcNy/4mPjd2ehxqak1dGgAA3cz8TYQAkEQ0oF/74QuLMwP4OSOqYuOehtRl9Wurdx7MhV3LthxIXVYyq3YcjHOvz4bMl9xeEwfcG7Hs3V61XDAMAFAGzN9ECABJRAOKeG9bfe4MnJteeyd1Wf1esViMP7xzWuZzvX/aqtRlJdHSVoiv3Dc7F/K8sWpX6tLoA1raCvHV++fkfh+vLNqcujQAALqR+ZsIASCJaEARVz0xPzN0nz+y2oIM3WTkK0szn+3XHnojdUlJ/HTqyly4I2Tm/dbvPhQXHLU4zAWjJsWG3c5EBgAoFeZvIgSAJFLuDWj+uj25YOaeqStSl1Uypi3fkflsPzx8YuxvKK9LXpds2h8fGZ5dEfl/3zU9GlvaUpdGH/PKos25fvTV++dES1shdWkAAHSDcp+/+TUBIEmUcwMqFovxtYfeyAzbg0dPiYNuvt9tDje35e57N+HtLanL6jWNLW3x+btn5ELQxRv3pS6NPuro+5EOHFoZd1QvT10WAADdoJznb/6DAJAkyrkBHX122sChlfHY7LWpyyo5Vz4+L/MZ//CF8lnc4OYJy3K/sXFTnGHKsR1sao3PjZ2e+c2cNawyZq90v0gAgP6unOdv/oMAkCTKtQEVCsX4k3tm5lZkbWp1WWZ3e+KNdZnP+ZM3T4lCoZi6rB43d/Xu3OIyX/7ZbJdzckJLNu2Pj47IXjY+5Japsdu9SQEA+rVynb/JEgCSRLk2oF8tzN9r698WlM/x96YNuxtyn/Xbm0r7Etj6xpa45PaazDGfc31VrNxen7o0+olHZ63J/d3838fnRbFY+uE5AECpKtf5mywBIEmUYwNqbi3E/7ozG858YdzMaCuDs9JSufSu7CWNP526MnVJPeqfX8rfx+3RWWtSl0U/UigU4+8em5f7HblNAQBA/1WO8zd5AkCSKMcGdPQlqQOHVsbUZdtTl1XSfvJa9l54f/7AnNQl9Zipy7bnfl9XPDy3LC57pnvtOtgUn7x5avZM0hFVsXTz/tSlAQBwEspx/iZPAEgS5daADjW1xidvnpIZqP/iwTdcVtfDZq3cmVvUYM+h5tRldbvdB5tyv68LRk2KjXsaUpdGP3X0387AoZVx6djpcchq5QAA/U65zd90TABIEuXWgO59fWVumK5btyd1WSWvqbUtBt1Qnfncf7Vwc+qyulWxWIxrnlqQ+329ULcxdWn0c7dVvZv7Xf34xfJZTRsAoFSU2/xNxwSAJFFODWjPoea4YNSkzBD9rfF1qcsqG1c9MT/z2f/guYWpS+pWLy/clAtprnqiztmlnLLm1kJ89b7Zud/XK4tKK0QHACh15TR/c2wCQJIopwY0ekL2PnRnDauMd7ceSF1W2XjmzfWZz/93fzK5ZBZe2bLvcFx4YzZcHjx6Suysb0pdGiVi/e5Duf+BceGoSbFht8vLAQD6i3Kavzk2ASBJlEsD2rzvcJwzoiozPP+/5xelLqusbN53OHcG04L1e1OXdcoKhWL8zaNv5o6tasnW1KVRYn61cHPud3bZ/XOipa2QujQAADqhXOZvjk8ASBLl0oB+/OLizND80RETLcyQwB+Pm5H5Hu6a/F7qkk7Zk3Pzq0pfJ1ymh1z3wqLc7+3O6uWpywIAoBPKZf7m+ASAJFEODWjl9vo4e1h2YL7x1XdSl1WWbpuYXczgyz+bnbqkU7Jm58E474bsmaW/f9vrsf9wS+rSKFEHm1rjs2Om5W5nMGfVrtSlAQBwAuUwf3NiAkCSKIcG9N0ns4tPfGxktXuzJTJ39e7c2Us76htTl3VSWtsKcdn9c3LHM3ulIIaetWTT/vjoiImZ393Ft0yN3Qf1NQCAvqwc5m9OTABIEqXegBas35sLaO6esiJ1WWWrpa2QW8jgxfkbU5d1Uu6rWZn7bY16ZWnqsigTP5+5Jvf7+9Z4q04DAPRlpT5/0zkCQJIo5QZULBbj6w/PzQzI//Mnk6O+0eWZKf390wsy38m1z7yVuqQuW7p5f3xkePYMrEvHTo/DzW2pS6NMFArF+OZj83Ih4ONz1qYuDQCAYyjl+ZvOEwCSRCk3oOnv7cgNx4/OWpO6rLL3Qt3GzHdy4Y2T+tUqpo0tbfGFcTMzx3D2sMpYuKH/r2hM/7Kzvik+efPUzG/xnBFVsXTz/tSlAQDQgVKev+k8ASBJlGoDKhSK8cWfzsoMxpfcXhONLc7QSm37gcZcMPvmmt2py+q0oxcyKZXVjOmfZq7Ymfs9Xjp2ehxqak1dGgAARynV+ZuuEQCSRKk2oFcWbc4Nxf31XnOl6E+PCmfvqF6euqROmbd2T5x11IrSX7p3VjS39p8zGCk9HYXS//zS4tRlAQBwlFKdv+kaASBJlGIDam4txB/eOS0zDP/R3TOireDm+H3FmEnLM9/Pn9wzM3VJJ3SwqTX+1501ucst39tWn7o0ylxzayG+ct/sXAj46uItqUsDAOB9SnH+pusEgCRRig3oqbnrcoPw5He2pS6L95m/bk/uO9q6/3Dqso5r2C/fztX8yMzVqcuCiIhYt+tQnD+yOnt/zVGTYuOehtSlAQDw70px/qbrBIAkUWoNqKG5NXdT/MsfmBPForP/+pLWtkJcdNPkzPf07LwNqcs6pprl23Ph39cfmuusUvqUlxduyv1O//yBOf1qkR0AgFJWavM3J0cASBKl1oDuq1nZrxeYKCfff3Zh5nv67pPzU5fUob2HmmPILdlQ+fyR1bFhtzOr6Huue35RrgeOmdQ/7rEJAFDqSm3+5uQIAEmilBrQ3kPNceGoSZnB98rH56Uui2P45VubcqFaU2vfWqW5WCzGtc+8lQtUnuvDZytS3g42tcZnx2TvgXrWsMp4Y/Wu1KUBAJS9Upq/OXkCQJIopQZ0awcrYS7bciB1WRzDroNNue9rzqq+FVJ0tJr0t8bXuaScPu3tTfviI8MnZn63f/HgG6nLAgAoe6U0f3PyBIAkUSoNaMu+w3HO9VWZgfcHzy1MXRYn8NWjVi69pXJZ6pLabdvfGB+/MXtG6e/+ZHLsONCYujQ4oUdmrs6dBbj3UHPqsgAAylqpzN+cGgEgSZRKA/qXl7IrtH5k+MRYv/tQ6rI4gXFTVmS+t8/fPSN1SRHx60t/v/nYvNzZf5Vvb01dGnRKY0tbnHdD9n+KvLZ4S+qyAADKWqnM35waAWAv2rFjR0yYMCFGjhwZX/ziF+N3fud32v8Ir7zyyi6/XnV1dVx++eUxYMCAOP3002PAgAFx+eWXR3V1dadfo6GhIcaMGRMXX3xx/Lf/9t/ijDPOiEGDBsWPfvSj2LCh5+43VgoNaNWO+jh7WDaoGfnK0tRl0QmLNu7LhWwb96RfXOPp2vW5upxRSn/zfx/Phtg/enFx6pIAAMpaKczfnDoBYC868gfX0daVALBYLMbVV1993Ne7+uqrT3i/sNWrV8d55513zNf4rd/6rZg4ceIpHnXHSqEBXfPUgsyQO+iG6thR7zLN/qBQKMYnRk/JfH9PzV2XtKZ1uw7FoBuqMzV96tapsb+hJWld0FWPz1mb+R1ffMtU968EAEioFOZvTp0AsBe9P1z70Ic+FF/4whdOKgAcMWJE+/MGDx4czz33XNTV1cVzzz0XgwcPbn/s+uuvP+ZrHDx4MAYNGtS+73e/+92oqamJuXPnxq233hq/+Zu/GRUVFfGBD3wg3n777W44+qz+3oA6OoPsrsnvpS6LLrju+UW5RTZSaSsU4/IH5uR+UzNX7ExWE5ys1TsP5n7L7261MBIAQCr9ff6mewgAe9GoUaNiwoQJsX379oiIWLduXZcDwFWrVsVpp50WFRUVMWTIkDh8+HDm8YaGhhgyZEhUVFTEaaedFqtXr+7wdW688cb29x4zZkzu8blz57a/z6WXXtq1A+2E/tyAisVifOOR2twiDQcananVnxy90u55N1RFY0tbkloemL4qF5hc/6slSWqBU1UsFuPTd9Rkfs8Pz+j43yIAAHpef56/6T4CwIROJgC89tpr259TW1vb4T61tbXt+3z/+9/PPd7S0hK//du/HRUVFfGxj30sCoVCh69zzTXXtL/OggULOn1cndGfG9DMFTtzYc3PZ65JXRZdtPdQc+4ejjN68Yy7hubWmLhka3z/2YXxkeETM3V8Zsy0aGhu7bVaoLsNf3lJ5jf9Vz/v+N8rAAB6Xn+ev+k+AsCEuhoAFovFGDBgQFRUVMSgQYOOu++Re/t98IMfzN17acqUKe3ve8cddxzzNd4fJI4YMaJTx9RZ/bUBFQrF+NK9szKD7e/f9nqyM8c4Nf/nwTcy3+WNr77To+93oLElXl64Ka5+an5updQj29nDKmPB+j09Wgf0tEnvbMv8rs8ZUSXUBgBIpL/O33QvAWBCXQ0A16xZ077/Nddcc9x9379IyNq1azOPjRw58oRnEUZEtLa2xhlnnBEVFRXxmc98plPH1Fn9tQG9tnhLLrB5oW5j6rI4SffVrMx8l58dM63b32PPoeZ4vm5DXPn4vPjoiIkdhn7v3+6sXt7tNUBvq29syZ3ZWrN8e+qyAADKUn+dv+leAsCEuhoAVlZWtu9/zz33HHffcePGte979Eq+X/va19of27dv33Ff56KLLoqKior47//9v5+wvq7ojw2opa0Qnx0zLTPQfv7uGdHa1vEl1PR9SzfvzwVwa3cdOuXX3XGgMZ6auy7+6ue18eHhJw79Bg6tjLOGVcZNr70TLX5PlIivPzw38xsf9crS1CUBAJSl/jh/0/0EgAl1NQB86KGH2vd/6aWXjrvvSy+91L7vww8/nHns937v96KioiLOOOOME77nn/3Zn7W/TlNT0wn3P2LTpk3H3erq6vpdA3q6dn0utKleui11WZyCYrEYF98yNfOdPjZ77Ymf2IFNexvi0Vlr4i8efCPOGnbiwG/g0Mr48PCJ8TePvhlP166PHfWN3Xx0kNb907KL23xu7PTUJQEAlCUBIBECwKS6GgCOGTOmff/q6urj7ltVVdW+71133ZV57Pzzz4+Kior4H//jf5zwPa+44or219m9e/cJ9z/iyHM6s/WHBnS4uS2GHBUUXXb/nNz9Fel//vmlxZnv9W//9c1OP3fNzoNx/7RV8eWfze5U4HfkXmjfGl8XL8zfGHsPNffgkUFaSzblz7DdsLshdVkAAGVHAEiEADCprgaAo0ePbt+/pqbmuPvW1NS073vzzTdnHvvwhz8cFRUV8aEPfeiE7/nNb37zpBpFqQWAD0xflRtk567ufCBK3zVxydZOL1ZQLBZj+bYDMW7KivjCuJmdDv3Ou6EqrnlqQbyyaHPUN7b08hFCGoVCMT4xekrmb+Gp2vWpywIAKDsCQCIEgEmV8hmApXYJ8IbdDfFPzy1sv7Tzm4/NS10S3eRAY0vuPn2vv/sfixUUi8V4e9O+uKN6eXxu7PROh34XjJoU//jswqhastXqp5Stf3puYebv4qon5qcuCQCg7AgAiRAAJlXK9wA8kf7agJZtORDfGl8XSzfvT10K3eiKoxYrGP7ykpi/bk+MnrAsLrm9ptOh3+/+ZHL8+MXFUbN8ezS1tqU+LEju5YWbMn8j54+sjuZWC90AAPSm/jp/070EgAl1NQCcMGFCt6wC/Bd/8RdWAYb3eWjG6k6HfEdvn7x5aox4eUnMXrnLCr5wlF0Hm3J/M7Vr3D4BAKA3mb+JEAAm1dUAcM2aNe37X3PNNcfd9+qrr27fd+3a7KqmI0eObH+strb2mK/R2toaZ5xxRlRUVMRnPvOZTh1TZ2lA9CXvbavvUuj3B7e9Hje99k7MW7sn2goWgoHj+bOfzcr8/dxRvTx1SQAAZcX8TYQAMKmuBoDFYjHOPPPMqKioiEGDBh1330GDBkVFRUUMGDAgt1Lt5MmT29/3jjvuOOZr1NbWtu83fPjwTh1TZ2lA9CXFYjH+4LbXjxv6fWbMtLit6t1YtHGf1Z+hC+6sXp75W/rSvbNSlwQAUFbM30QIAJPqagAYEfG9733vhGfvvT+4u/baa3OPNzc3x2/91m9FRUVFfOxjHztmmHHNNde0v05dXV2nj6szNCD6mrunrMiFfn9094y4e/J7sWzLAaEfnKQ31+zO/W3trO++e8oCAHB85m8iBIBJnUwAuGLFijjttNOioqIihgwZEocPH848fvjw4RgyZEhUVFTEaaedFitXruzwdd5/GfCYMWNyj8+dO7f9fT772c929dBOSAOir2lsaYt7pq6Iv396QdxXszJW7TiYuiQoCS1thbhg1KRMAPjLt/R9AIDeYv4mQgDYq2bPnh3jx49v38aOHdv+R/jpT38689j48eOP+TrDhg1rf97gwYPj+eefj/nz58fzzz8fgwcP7tRlu/X19XHuuee273v11VfHtGnTora2Nm677bb4zd/8zaioqIj//J//cyxatKjbPwsNCKB8fOfJ+ZkA8AfPLUxdEgBA2TB/EyEA7FVXXnll+x9dZ7ZjKRQK8e1vf/u4z73qqquiUDj+iqSrVq2Kc84555iv8V//63+NCRMmdPfHEBEaEEA5ebp2fSYAHDx6ShQsoAMA0CvM30QIAHtVdwWAR0ycODEuu+yyOPPMM+P000+PM888My677LKoqqrqdE2HDh2KO++8M4YMGRK//du/HR/4wAfivPPOi+uuuy7Wr19/Kod7XBoQQPnYuKchdx/AtzftS10WAEBZMH8TIQAkEQ0IoLxcOnZ6JgC8r6bje9QCANC9zN9ECABJRAMCKC83vvpOJgD8+kNzU5cEAFAWzN9ECABJRAMCKC/Tlu/IBIAfHj4xDjS2pC4LAKDkmb+JEACSiAYEUF4amlvjnBFVmRCweum21GUBAJQ88zcRAkAS0YAAys/fPPpmJgAc9sslqUsCACh55m8iBIAkogEBlJ9HZq7OBICX3F4TxWIxdVkAACXN/E2EAJBENCCA8rN824FMADhwaGWs2nEwdVkAACXN/E2EAJBENCCA8lMsFuNTt07NBICPzV6buiwAgJJm/iZCAEgiGhBAefrxi4szAeCVj89LXRIAQEkzfxMhACQRDQigPE14e0smADzvhqpobGlLXRYAQMkyfxMhACQRDQigPO1raI6zh2XvAzhr5c7UZQEAlCzzNxECQBLRgADK158/MCcTAN48YVnqkgAASpb5mwgBIIloQADla9yUFZkA8I/HzUhdEgBAyTJ/EyEAJBENCKB8LVi/NxMADhxaGVv2HU5dFgBASTJ/EyEAJBENCKB8tbYV4qKbJmcCwOfrNqQuCwCgJJm/iRAAkogGBFDern3mrUwAeO0zb6UuCQCgJJm/iRAAkogGBFDeXqjbmAkAP37jpGhtK6QuCwCg5Ji/iRAAkogGBFDetu4/nLsP4IL1e1OXBQBQcszfRAgASUQDAuAL42ZmAsC7p6xIXRIAQMkxfxMhACQRDQiAWyqXZQLAy+6fk7okAICSY/4mQgBIIhoQALNX7soEgGcNq4y9h5pTlwUAUFLM30QIAElEAwKgsaUtzruhKhMCvrZ4S+qyAABKivmbCAEgiWhAAEREXPn4vEwA+KMXF6cuCQCgpJi/iRAAkogGBEBExONz1mYCwE/dOjWKxWLqsgAASob5mwgBIIloQABERKzeeTATAA4cWhnLtx1IXRYAQMkwfxMhACQRDQiAiIhisRifvqMmEwA+PGN16rIAAEqG+ZsIASCJaEAAHDH85SWZAPCvH61NXRIAQMkwfxMhACQRDQiAIya9sy0TAJ4zoioamltTlwUAUBLM30QIAElEAwLgiPrGlvjI8ImZELBm+fbUZQEAlATzNxECQBLRgAB4v68/PDcTAI56ZWnqkgAASoL5mwgBIIloQAC83/3TVmUCwM+NnZ66JACAkmD+JkIASCIaEADvt2TT/kwAOHBoZWzY3ZC6LACAfs/8TYQAkEQ0IADer1AoxidGT8kEgE/Vrk9dFgBAv2f+JkIASCIaEABH+6fnFmYCwO88OT91SQAA/Z75mwgBIIloQAAc7eWFmzIB4Pkjq6O5tZC6LACAfs38TYQAkEQ0IACOtutgU+4+gLVrdqcuCwCgXzN/EyEAJBENCICO/NnPZmUCwDuql6cuCQCgXzN/EyEAJBENCICO3Fm9PBMAfuneWalLAgDo18zfRAgASUQDAqAjtWt25y4D3lnflLosAIB+y/xNhACQRDQgADrS3FqIC0ZNygSAv3zLvxMAACfL/E2EAJBENCAAjuU7T87PBID/9NzC1CUBAPRb5m8iBIAkogEBcCxP167PBICDR0+JQqGYuiwAgH7J/E2EAJBENCAAjmXjnobcfQCXbNqfuiwAgH7J/E2EAJBENCAAjufSsdMzAeB9NStTlwQA0C+Zv4kQAJKIBgTA8dz46juZAPDrD81NXRIAQL9k/iZCAEgiGhAAxzNt+Y5MAPiR4RPjQGNL6rIAAPod8zcRAkAS0YAAOJ6G5tY4Z0RVJgSsXrotdVkAAP2O+ZsIASCJaEAAnMhfP1qbCQCHv7wkdUkAAP2O+ZsIASCJaEAAnMgjM1dnAsBLbq+JYrGYuiwAgH7F/E2EAJBENCAATmT5tgOZAHDg0MpYvfNg6rIAAPoV8zcRAkAS0YAAOJFisRifunVqJgB8bPba1GUBAPQr5m8iBIAkogEB0Bk/fnFxJgC88vF5qUsCAOhXzN9ECABJRAMCoDMmvL0lEwCed0NVNLa0pS4LAKDfMH8TIQAkEQ0IgM7Y19AcZw/L3gdw1sqdqcsCAOg3zN9ECABJRAMCoLMuu39OJgC8pXJZ6pIAAPoN8zcRAkAS0YAA6KxxU1ZkAsA/HjcjdUkAAP2G+ZsIASCJaEAAdNaC9XszAeDAoZWxdf/h1GUBAPQL5m8iBIAkogEB0FmtbYW46KbJmQDw+boNqctKatHGfXHVE3Vx7TNvxZqdB1OXAwD0YeZvIgSAJKIBAdAV1z7zViYAvPaZt1KXlMyslTvj3Our2j+LT4yeIgQEAI7J/E2EAJBENCAAuuKFuo2ZAPDjN06K1rZC6rJ63eyVuzLh35HtkttrYtv+xtTlAQB9kPmbCAEgiWhAAHTF1v2Hc6HXgvV7U5fVq44V/r1/cZR9Dc2pywQA+hjzNxECQBLRgADoqi+Mm5kJvMZNWZG6pF4zZ9Xxw78j2+UPzImG5tbU5QIAfYj5mwgBIIloQAB01S2VyzJh12X3z0ldUq84Vvj3vWcWxKVjp+f++5WPz4uWMrw8GgDomPmbCAEgiWhAAHTVrJU7M0HX2cMqY++h0r7k9Y1Vu+K8G/Lh3/efXRitbYXYtLchfu/W13OP/+C5hVEoFFOXDwD0AeZvIgSAJKIBAdBVjS1tuTDstcVbUpfVY44V/v3DL97KLICyYnt9XHTT5Nx+N776ThSLQkAAKHfmbyIEgCSiAQFwMq58fF4m5Prxi4tTl9Qj3ljdcfh37VHh3xFvbdgbg26ozu1/X83KBNUDAH2J+ZsIASCJaEAAnIzH56zNBFyfunVqyZ3lNnf17o7Dv2c6Dv+OmP7ejvjI8Im55z3z5vperB4A6GvM30QIAElEAwLgZKzeeTAXcC3fdiB1Wd2mds3uDs/k+94zCzq1sMcrizbnnnvWsMqYuGRrL1QPAPRF5m8iBIAkogEBcDKKxWJ8+o6aTMD1yMzVqcvqFscK//7+6c6Ff0eMP+osyYFDK+OcEVUxZ9WuHqweAOirzN9ECABJRAMC4GQNf3lJJtz660drU5d0yt7spvDviLsnv5d7rfNHVsfbm/b1QPWlbX9DS2zedzh1GQBw0szfRAgASUQDAuBkTXpnW+7stobm1tRlnbR5a/fEx0bmw79rnjq58C/i12dKjjgqKB04tDIGj54Sq3ce7OYjKF0vL9wUZw/79Wd3/a+WlNz9JgEoD+ZvIgSAJKIBAXCy6htbcotd1Czfnrqsk3Ks8O/qp+afdPh3RFuhGNf+4q3ca19ye01s3e+MthPZUd+YOytz5oqdqcsCgC4zfxMhACQRDQiAU/H1h+ZmgpkbX30ndUldVreu4/Dvu0/Oj+bWUwv/jmhqbYu/efTN3Hv80d0zYu+h5m55j1I16pWluc/tq/fNdhYgAP2O+ZsIASCJaEAAnIr7p63KBDOfGzs9dUldMn/dnji/g/DvO90Y/h1xsKk1vnrf7Nx7/fkDc/r1pdM9aeOehvjoiIm5z2zg0MqYuqx/nm0KQPkyfxMhACQRDQiAU7Fk0/5cMLNhd0PqsjqlN8O/I/Ycao5L75qee89vPjavx96zP7vu+UUdhn8Dh1bGF386KwoFZwEC0H+Yv4kQAJKIBgTAqSgUivGJ0VMywcxTtetTl3VCC9Z3HP5d9UTPhX9HbN53OH7/ttdz7/2Pzy4UaL3Pe9vq46xhHYd/R7aJS7amLhMAOs38TYQAkEQ0IABO1T89tzB3Bl1ftmD93rhg1KQOwr+6XjsLb9WO+vjdn0zO1XDjq++4t92/+86T8zOfzfkjq+NzY7NnT/7R3TOiTWgKQD9h/iZCAEgiGhAAp+rlhZsyocwFoyb12ctZjxX+fXt8XTS1tvVqLQs37O1w8ZF7X1/Zq3X0RW9t2Jv7XO6esiImLtma+++/Wrg5dbkA0CnmbyIEgCSiAQFwqnYdbMqFMrVrdqcuK+etDR2Hf99KEP4dMXPFzg4XuegPl1H3lGKxGN94pDbzefzPn0yO+saWKBSK8cWfzso89tkx06K1rW8GzgDwfuZvIgSAJKIBAdAdvnRvNpS5s3p56pIyFm7YGxf2sfDviNcWb8nd6+6sYZUx4e0thUMlWgAAIABJREFUSetKZdbKnbnv6ecz17Q/PnXZ9tzjL9RtTFgxAHSO+ZsIASCJaEAAdIc7q5dnApkv3TsrdUntjhX+/d/H5yUP/454cu66XH0fHTExZq/clbq0XlUsFuMr983OfA6/d+vr0djSltnnq/fPyexzye01ffaycwA4wvxNhACQRDQgALpD7ZrduQBrZ31T6rJi0cZ9HYZ/Vz4+LxMq9QXjpqzI1fmxkdWxeOO+1KX1mqoO7vH37LwNuf1mrsifJVjOl00D0D+Yv4kQAJKIBgRAd2huLeTur/dU7fqkK7Qu2rgvLrwxH/793WN9L/yL+PWZbSNfWZqr93/+ZHKs2nEwdXk9rrWtEP/7ruwqv58bO73D+/sVi8X42kNvZPb91K1T++T3CgBHmL+JEACSiAYEQHf5zpPzc+HVuddXxZ/cMzP+4RdvxbgpK+LVxVvinS37ezyoWdzPwr8jCoVi/MMv3srV/Qe3vR5b9h1OXV6PemH+xtxxH+8+iB2ddfqvs9f2YsUA0DXmbyIEgCSiAQHQXZ6uXZ8LZI61nTWsMj59R0383WPzYvSEZfGLNzfEm2t2x66DTVEsntpZg8cK/77Zx8O/I5pbC/G3//pmrv7P3z0j9h5qTl3e/2fvzsOjrO+9j49COG0pV6VHzyLH4oa4IF1wOXpa+6hPLVq32vJ4rO1zyiOtxaU9tT0FwqZEoII7IFrcAFlUUMRsEBIgJKwhLAESErYQliwsWUlmMnN/nj9ap/y4k5CEmfxmeb+ua/5o5s49n0mv+V58P87MHRZNzX7dOjnT9T2SgbO8g/Rns8yrBQ9KWq4Gb3MXpQYAoGPYvyFRAMISBhAAIFQqahtdHwPuzO2bzy3TQ2/k6n8+3qo3V+3Ril3l2l9V3+JHQc+0razl8u/nb6+PivLvC/VNza4LXfQdkaz7p+eovin2Cq531uxzPdeVRRVn/b28Aydcvzdz1Z4uSAwAQMexf0OiAIQlDCAAQCjl7qnSI39Z12IJd663fompuuvl1Rr+QZ5eXFakT/MPqeBQdbAQ215WretjoPz7wvF6r+s78b54PrF0xdu6pmZ9Z8Jy4zkOeXNtu98J+st3N7gK5NpGX5hTAwDQcezfkCgAYQkDCAAQDo7jqLK2SWv3HNPcdQf07NId+sU7G1wf8wzV7ZZJK1p892G0ln9fOHzylG6ZtML1vJ6an3/Wj8dGi1czil3PL+/A8Xb//vayatfvv7aiOIyJAQDoHPZvSBSAsIQBBADoag3eZhUcqtaSLYf00rIiPfHBZv3wldXqNzo1pKXgo7Oiu/z7QklFnb713DLX8xu7pOCcvy/RtuP1Xldx+//e29jh8/x6jnkBmgHj01XdwLsAAQCRhf0bEgUgLGEAAQAihT/g6MCxemUWlusvq/dqxKJt+skbufpmC+XX2W4/m7VOp7zRX/59YcvBk7pmbJrreb6Ssdt2tHPyfPJO4/lcOjJZu47UdPg8hUdrdOlI828zNb0oDIkBAOg89m9IFICwhAEEAIgGx+u92rj/uOZvKFXS5zv1y3c36LsvZLpKn1gs/76QXVypKxNTXM93zroDtqN1ypHqU653ff52QX6nz/fkvM3Gua4Zm6ZjdU0hTAwAwLlh/4ZEAQhLGEAAgGjW6PNr15Eafb7tsKZnlWhRXlm7rhYcrT7fdthVel4+KkU5JVW2o3XYyMXbjOdxxagUHThW3+nzlVTU6bIz/jYTU3aFMDEAAOeG/RsSBWDUamxs1IwZM3THHXfowgsvVEJCgi6++GLdc889WrhwYbvOceDAAY0YMULf+c539LWvfU3du3dX7969dcstt2jChAmqrKwMW34GEAAA0WXOugOudwEOfHbZOZVnXW1vZZ0uH2W+mzHxk+3nfN7ff7jFOGf/MamqqGkMQWIAAM4d+zckCsCoVFRUpP79+wdfwC3dBg8erPr61v9BPm/ePH3lK19p8xz/+I//qMzMzLA8BwYQAADR56VlRa4S8H+/tEq1jdFx4YszP67bf0yqykNQ1B04Vq8rzigWx3+2IwSJAQA4d+zfkCgAo05lZaUuueSS4It3yJAhSk5OVn5+vpKTkzVkyJDgfffdd1+L51i7dq26desmj8ej888/X0OHDtWSJUu0ceNGLVq0SPfdd1/wHD179tT+/ftD/jwYQAAARJ9AwHFd+bbviGQ99v5GBQKRfWXggkPVrtyTUwtDdv4zP1rcLzFVh0+eCtn5AQDoLPZvSBSAUefJJ58MvnDHjx/f4jHjxo0LHrN48WLX/ffee2/w/hkzZrR4jmeeeSZ4zNNPPx3KpyCJAQQAQLSqb2rWD19Z7SrTIv3qt//17gYj74Dx6apuCN07Fw+dPKV+iebFRUYuPvePFwMAcK7YvyFRAEYVv9+vCy64QB6PR3379pXf3/KVBv1+v77xjW/I4/HohhtucN3fu3fv4Ed8W1NdXR0cEIMGDQrZc/gCAwgAgOh18HiDvvXcMlcJ+Pm2w7ajtWjDvuOurNOzSkL+OOOWFLguMFJ6rCHkjwMAQEewf0OiAIwqhYWFwRftsGHD2jz2scceCx575kd4e/bs2Wo5eLoLL7xQHo9HAwYMONfoLgwgAACiW+6eKtcFNfqPSVXBoWrb0QyO4+gnb+QaOQclZajB2xzyx6qoadRVo813AT7z4daQPw4AAB3B/g2JAjCq5ObmBl+0o0ePbvPYxMTE4LGzZ8827vv2t7991ncA1tTUBH//oYceCkn+0zGAAACIfnPW7ne9s+6WSStUVddkO1pQZmG5K+P7ufvD9njPJ+80HuuykcnaU1kXtscDAOBs2L8hUQBGla1btwZftE899VSbx57+XYEjRoww7nvzzTeD982cObPF3//jH/8YPGbZsmUhew5fYAABABD9HMfRyMXbXQXbT2fmytscsB1PgYDj+r7C//hzZlizHatr0jVj04zHfHp+ftgeDwCAs2H/hkQBGFXq6+uVkJAgj8ejgQMHtnns9ddfH3yBP/LII8Z9fr9fjz76aPAqwMOGDdPSpUu1adMmLV68WD/+8Y9bLQ/bq6ysrM3bxo0bGUAAAMQAb3NAQ2audZWAIxdvk+PYvTLwki2HXLkW5YX/3x1T0guNx7x0ZLKKjtaG/XEBAGgJBSAkCsCoM3jw4OALd/78+S0eM3/+/OAxHo9H9957b4vHffjhh8GPA595u/3228/pnX8tnbO1GwMIAIDoVlXXpFsnZ7rKttlr91vL5PMHdNuULCPPD15eJX8g/KXkyQavBoxLNx778Tl5YX9cAABaQgEIiQIw6mzYsEHdu3eXx+NRQkKCkpKSVFpaKp/Pp9LSUiUlJSkhIUE9evQIvsDvvPNO13kKCwv1wAMPBM915u1LX/qSHn30UR05cqRTOSkAAQCILzsOV6v/GPMCGJePSlHunioreeauO+AqJNN3HO2yx38lY7fr8SPtAikAgPhAAQiJAjAqzZ492yj4zrx169ZN06ZNC/7vBx980Pj97OxsXXDBBfJ4POrbt6/mzp2r8vJy+Xw+lZWVacaMGerdu7c8Ho/+7d/+Tbt27epwRj4CDABA/Pl822FX6fWt55bp4PGGLs1xyuvXjc9nGDkemJ7TpR9Jrmn06ZvPLTMyDH1vY5c9PgAAX6AAhEQBGLW2bt2qIUOGqFevXsEX8vnnn68777xT69evV0FBQfDnQ4cODf5eU1OT+vTpI4/Ho3/5l3/R0aMt/5fwHTt26Etf+pI8Ho9uuOGGkOdnAAEAEJteXFbkKgF/+Mpq1Tc1d1mGmav2uDLYeCfijJUlrhx5B050eQ4AQHxj/4ZEARj1/H6/ysrKVFJSooaGv//X9Xnz5gVf4FOnTg3+fMmSJcGfT5w4sc1zDxs2LHjs1q1bQ5qbAQQAQGwKBBwNm73JVXz9es4mBbrg+/eqT/k08FnznXc/f3t92B+3JQ3eZg1KWm5keXSWnSwAgPjF/g2JAjBmDR8+PPgCz87ODv588uTJwZ+npaW1eY6ZM2cGj124cGFI8zGAAACIXXVNzfrBy6tcJeBLy3eH/bGnprvfgbit7GTYH7c1s7L3uvKs23vMWh4AQPxh/4ZEARiTvF6vLrroInk8HvXp00d+vz9439SpU4Mv/M8//7zN87z++uvBYxctWhTSjAwgAABi24Fj9a7vwOs7Ilmp2zt3gbH2qKxt0jVj04zH+81cu1ffbfT5ddNE8/sIh8xc26XfRwgAiG/s35AoAGPSlClTgi/upKQk475FixYF7/vTn/7U5nl+8pOfBI/dvHlzSDMygAAAiH05JVW6fFSKUX5dPSZNOw/XhOXxxn+2w3isy0Ymq6SiNiyP1RFz1u53FaHZxZW2YwEA4gT7NyQKwKhUWlra6n1Lly5VQkKCPB6P+vXrp8bGRuP+kydP6itf+Yo8Ho969eql7du3t3ie1NRUnX/++cF3EQYCgZA+BwYQAADx4d2cfa7y69bJmTpW1xTSxzl4vEFXJppl4x8/Cu13GHdWU7Nft07ONLLd38VXJQYAxC/2b0gUgFGpV69euuuuuzRr1iytXbtWeXl5WrRokR5++OHgi7p3797Kz89v8fcnTJgQPO6rX/2qRo0apaysLG3ZskXp6ekaPny4unfvHjxm7ty5IX8ODCAAAOKD4zj6n4+3ukrA//PmWvn8ofsPjM98aD5Gv8RUHTp5KmTnP1cLN5a6/gYrdpXbjgUAiAPs35AoAKNSz549gy/elm7XXnttq+Wf9Nd/iP/3f/+3zjvvvDbPk5CQYFxBOJQYQAAAxI+mZr8eeiPXVYCN/rTlTyJ0VHF5rS4baZ772aU7QnLuUPH5A7ptSpaR8e5Xs7vkysgAgPjG/g2JAjAqLViwQEOHDtV1112nr3/96+rRo4f69Omju+++W++88458Pl+7zpOXl6ff/OY3GjBggHr16qVu3brpa1/7mgYNGqRnnnlGu3eH70p9DCAAAOJLZW2T/n3SClcJOHfdgXM+96/nbDLOec3YNFWF+CPGofBJflmXXhQFAACJ/Rt/RQEIKxhAAADEn+1l1bpqdKpRgF0xKkXr9h7r9Dm3HDzpKtVeWlYUwtSh4w84uvOlVUbWH7y8Sn7eBQgACCP2b0gUgLCEAQQAQHxasuWQq7D79oTlOni8oVPne+Qv64xzffO5ZappbN+nIWz4fNth1/NfsuWQ7VgAgBjG/g2JAhCWMIAAAIhff04rdJVgP3xltRq8zR06z5riKtd5/rJ6b5hSh0Yg4OiHr6w2Mv+vqSvVHMILogAAcDr2b0gUgLCEAQQAQPzyBxwNfW+jq7wb/kGeHKd9H4d1HEf3T1tj/P7NE1eo0ecPc/pzt2zHUddz/3DTQduxAAAxiv0bEgUgLGEAAQAQ32obfa7vw+s7IlmvrShu1++nFRxx/e78DaVhTh0ajuPovjPKy//4c6a8zbwLEAAQeuzfkCgAYQkDCAAA7Kuq1/Xj011FXvqOo23+XksX04i2j9GuLKoIyxWRAQA4E/s3JApAWMIAAgAAkrR6d6UuG2kWYdeOTVPh0ZpWf+ejTQdd5dnSrYe7MPW5cxxHP3kjNyo/wgwAiC7s35AoAGEJAwgAAHxhVvZeV6H33Rcydbze6zq2qdmvWydnGsfe/Wq2AoH2fXdgJMnd476IyTtr9tmOBQCIMezfkCgAYQkDCAAAfMFxHD3z4VZXGfafb62T74yP9b6bs891XFZRhaXk5+4/31pnPJdBSRk65eVdgACA0GH/hkQBCEsYQAAA4HSNPr8emJ7jKvfGLSkIHlPf1KzvTFhu3D9k5tp2Xzk4Em3af9z1nN9ctcd2LABADGH/hkQBCEsYQAAA4EwVNY26aWKGqxBb8Ler+76+oth136b9xy2nPnf/950NxnP61nPLVNfUbDsWACBGsH9DogCEJQwgAADQkq0HT6rf6FSjELsyMUXLd5ZrwDjzisFD39toO25IbCs76So2X19RbDsWACBGsH9DogCEJQwgAADQmk/zD7kKsTNvl45M1q4jrV8pONoMm73JeH4DxqerusFnOxYAIAawf0OiAIQlDCAAANCWSSm72iwAf7sg33bEkNp1pMb1HF9cVmQ7FgAgBrB/Q6IAhCUMIAAA0BZ/wNF/vbuhxfLvilEpOnCs3nbEkHti3mbjeV47Nk3H6722YwEAohz7NyQKQFjCAAIAAGdTfcqn219c6SoAEz/ZbjtaWJRU1OqykeZznZSyy3YsAECUY/+GRAEISxhAAACgPfZU1mnA+L9f/OOasWkqr2m0HStsfr9wi1EA9h+TqmN1TbZjAQCiGPs3JApAWMIAAgAA7bXjcLUefmutHnojV5v2H7cdJ6z2V9Xr8lEpRgn49pp9tmMBAKIY+zckCkBYwgACAABo2W8X5BsF4OBXs21HAgBEMfZvSBSAsIQBBAAA0LI1xVWu7z3ccbjadiwAQJRi/4ZEAQhLGEAAAAAt8wcc3TJphVEAPrt0h+1YAIAoxf4NiQIQljCAAAAAWjc1vcgoAL89Ybm8zQHbsQAAUYj9GxIFICxhAAEAALRuX1W962PAy3YctR0LABCF2L8hUQDCEgYQAABA237yRq5RAP5q9ibbkQAAUYj9GxIFICxhAAEAALRtwYZSowC8YlSKjtU12Y4FAIgy7N+QKABhCQMIAACgbTWNPvUfk2qUgO+s2Wc7FgAgyrB/Q6IAhCUMIAAAgLP73YJ8owC8+9Vs25EAAFGG/RsSBSAsYQABAACc3ZriKtfFQHYcrrYdCwAQRdi/IVEAwhIGEAAAwNn5A45umbTCKACfW7rTdiwAQBRh/4ZEAQhLGEAAAADtMyW90CgAvz1hubzNAduxAABRgv0bEgUgLGEAAQAAtM/eyjrXx4CX7ThqOxYAIEqwf0OiAIQlDCAAAID2e+iNXKMA/NXsTbYjAQCiBPs3JApAWMIAAgAAaL/5G0qNAvCKUSk6VtdkOxYAIAqwf0OiAIQlDCAAAID2q2n06arRqUYJ+G7OPtuxAABRgP0bEgUgLGEAAQAAdMxvF+QbBeA9r2XbjgQAiALs35AoAGEJAwgAAKBjsosrXRcD2Xm4xnYsAECEY/+GRAEISxhAAAAAHeMPOPr3SSuMAnDC5zttxwIARDj2b0gUgLCEAQQAANBxU9ILjQLwOxOWy+cP2I4FAIhg7N+QKABhCQMIAACg4/ZW1rk+Brx8Z7ntWACACMb+DYkCEJYwgAAAADrnoTdyjQLw13M22Y4EAIhg7N+QKABhCQMIAACgc+ZvKDUKwCtGpehYXZPtWACACMX+DYkCEJYwgAAAADqnptGnq0anGiXguzn7bMcCAEQo9m9IFICwhAEEAADQeU/PzzcKwHtey7YdCQAQodi/IVEAwhIGEAAAQOet3l3puhjIriM1tmMBACIQ+zckCkBYwgACAADoPH/A0c0TVxgFYNLnO23HAgBEIPZvSBSAsIQBBAAAcG5eSCs0CsBBScvl8wdsxwIARBj2b0gUgLCEAQQAAHBu9lTWuT4GnLGz3HYsAECEYf+GRAEISxhAAAAA5+7HM3KMAvDxOXm2IwEAIgz7NyQKQFjCAAIAADh389aXGgXglYkpOl7vtR0LABBB2L8hUQDCEgYQAADAuas+5dNVo1ONEvC9nH22YwEAIgj7NyQKQFjCAAIAAAiNp+fnGwXgj17Pth0JABBB2L8hUQDCEgYQAABAaKzeXem6GMiuIzW2YwEAIgT7NyQKQFjCAAIAAAgNf8DRzRNXGAVg0uc7bccCAEQI9m9IFICwhAEEAAAQOi+kFRoF4KCk5fL5A7ZjAQAiAPs3JApAWMIAAgAACJ09lXWujwGv2FVuOxYAIAKwf0OiAIQlDCAAAIDQenBGjlEA/mZunu1IAIAIwP4NiQIQljCAAAAAQuuD9QeMAvDKxBSdqPfajgUAsIz9GxIFICxhAAEAAIRW9Smf+o1ONUrA93P3244FALCM/RsSBSAsYQABAACE3lPz840C8N7X19iOBACwjP0bEgUgLGEAAQAAhN6q3ZWui4EUHq2xHQsAYBH7NyQKQFjCAAIAAAg9f8DRTRMzjALw+eSdtmMBACxi/4ZEAQhLGEAAAADh8ee0QqMAHJSUIZ8/YDsWAMAS9m9IFICwhAEEAAAQHiUVda6PAa/YVW47FgDAEvZvSBSAsIQBBAAAED4PzsgxCsDfzM2zHQkAYAn7NyQKQFjCAAIAAAifD9YfMArAKxNTdKLeazsWAMAC9m9IFICwhAEEAAAQPtWnfOo3OtUoAd/P3W87FgDAAvZvSBSAsIQBBAAAEF5Pzc83CsD7pq2xHQkAYAH7NyQKQFjCAAIAAAivlUUVrouBFB2ttR0LANDF2L8hUQDCEgYQAABAePkDjm6amGEUgBNTdtmOBQDoYuzfkCgAYQkDCAAAIPwmpxYaBeCgpAw1+wO2YwEAuhD7NyQKQFjCAAIAAAi/kopa18eAMwvLbccCAHQh9m9IFICwhAEEAADQNR6YnmMUgMM/yLMdCQDQhdi/IVEAwhIGEAAAQNeYu+6AUQD2S0zViXqv7VgAgC7C/g2JAhCWMIAAAAC6RnWDT/1Gpxol4Oy1+23HAgB0EfZvSBSAsIQBBAAA0HWenLfZKADvm7bGdiQAQBdh/4ZEAQhLGEAAAABdZ2VRhetiIEVHa23HAgB0AfZvSBSAsIQBBAAA0HX8AUc3TcwwCsCJKbtsxwIAdAH2b0gUgLCEAQQAANC1JqcWGgXgDc9nqNkfsB0LABBm7N+QKABhCQMIAACga5VU1Lo+BpxVWGE7FgAgzNi/IVEAwhIGEAAAQNd7YHqOUQA+8cFm25EAAGHG/g2JAhCWMIAAAAC63px1B4wCsF9iqk42eG3HAgCEEfs3JApAWMIAAgAA6HrVDT71S0w1SsA5a/fbjgUACCP2b0gUgLCEAQQAAGDHE/M2GwXg/dPW2I4EAAgj9m9IFICwhAEEAABgR1ZRhetiILvLa23HAgCECfs3JApAWMIAAgAAsKPZH9CNz2cYBeCklF22YwEAwoT9GxIFICxhAAEAANgzKXWXUQDe8HyGmv0B27EAAGHA/g2JAhCWMIAAAADsKS6vdX0MOKuwwnYsAEAYsH9DogCEJQwgAAAAu+6fnmMUgE98sNl2JABAGLB/Q6IAhCUMIAAAALvmrDtgFID9ElNV3eCzHQsAEGLs35AoAGEJAwgAAMCu6gaf+iWmGiXgnHUHbMcCAIQY+zckCkBYwgACAACw74l5m40C8P7pObYjAQBCjP0bEgVg1GpsbNSMGTN0xx136MILL1RCQoIuvvhi3XPPPVq4cGGHzrVhwwYNHz5cV199tXr16qWePXvq8ssv1z333KOXXnpJlZWVIc/PAAIAALAvq6jCdTGQ4vJa27EAACHE/g2JAjAqFRUVqX///sEXcEu3wYMHq76+vs3zNDU1adiwYTrvvPPaPNenn34a8ufAAAIAALCv2R/Qjc9nGAXgpNRdtmMBAEKI/RsSBWDUqays1CWXXBJ88Q4ZMkTJycnKz89XcnKyhgwZErzvvvvua/U8Xq9Xd999d/DY733ve5o1a5ZycnK0fv16ffjhh0pMTFS/fv0oAAEAAGLYpJRdRgF44/MZavYHbMcCAIQI+zckCsCo8+STTwZfuOPHj2/xmHHjxgWPWbx4cYvHjB07NnjMiy++2OZj+nyhvxocAwgAACAy7C6vdX0MOKuownYsAECIsH9DogCMKn6/XxdccIE8Ho/69u0rv9/f6nHf+MY35PF4dMMNN7ju37t3rxISEuTxePTLX/4y3LFbxAACAACIHPdPW2MUgE/M22w7EgAgRNi/IVEARpXCwsLgi3bYsGFtHvvYY48Fj92/f79x34gRI+TxeHTeeedp3759YUzcOgYQAABA5Jizdr9RAPZLTNWJeq/tWACAEGD/hkQBGFVyc3ODL9rRo0e3eWxiYmLw2NmzZxv3XX755fJ4PLrxxhuDPwsEAiorK9O+fft06tSpsOQ/HQMIAAAgcpxs8KpfYqpRAk5M4WIgABAL2L8hUQBGla1btwZftE899VSbx57+XYEjRowI/ryysjL489/+9reqqanR7373O/Xu3Tv48+7du+u2225TcnJy2J4LAwgAACCy/G5BvutdgAePN9iOBQA4R+zfkCgAo0p9fX3wu/sGDhzY5rHXX3998AX+yCOPBH++atUqoxi84oorgv+7pdvvf//7TmUtKytr87Zx40YGEAAAQATZX1WvKxNTjBLwSb4LEACiHgUgJArAqDN48ODgC3f+/PktHjN//nyjxLv33nuD933yySfBn//DP/yDPB6Pbr31Vq1evVqnTp3SiRMnNG/ePP3rv/5r8LiZM2d2OGdbpeKZNwYQAABAZHhu6U7XFYE3l56wHQsAcA4oACFRAEadDRs2qHv37vJ4PEpISFBSUpJKS0vl8/lUWlqqpKQkJSQkqEePHsEX+J133hn8/blz5xrl26BBg9TY2Oh6nOLiYvXs2VMej0cXXXRRh78XkAIQAAAg+pxs8Or68elGAfjQG7lyHMd2NABAJ1EAQqIAjEqzZ882Cr4zb926ddO0adOC//vBBx8M/u7HH39sHJuent7q4/zxj38MHrd06dIOZeQjwAAAANFpVvZe17sAU7cfsR0LANBJFICQKACj1tatWzVkyBD16tUr+EI+//zzdeedd2r9+vUqKCgI/nzo0KHB30tPTw/+vEePHvJ6va0+RkZGRvDYsWPHhjQ/AwgAACAyNTX79b0XsowC8LYpWfI2B2xHAwB0Avs3JArAqOf3+1VWVqaSkhI1NPz9Km3z5s0LvsCnTp0a/PnOnTuDP7/kkkvaPHdRUVHw2McffzykuRlAAAAAkSt52xHXuwDfXrPPdiwAQCewf0OiAIxZw4cPD77As7Ozgz/3+XzBKwlffPHFbZ7j9LLwySefDGk+BhAAAEDkchxvv/2LAAAgAElEQVRHP56RYxSAA59dppMNrX96BAAQmdi/IVEAxiSv16uLLrpIHo9Hffr0kd/vN+6/7bbbgt8VWF9f3+p5li5dGhwSkyZNCmlGBhAAAEBkyztwwvUuwKTPd9qOBQDoIPZvSBSAMWnKlCnBF3dSUpLr/tdeey14/7x581o9zy9/+cvgcWvWrAlpRgYQAABA5Hti3majALwyMUUHjrX+H5ABAJGH/RsSBWBUKi0tbfW+pUuXBj/i269fPzU2NrqOqaur0z/90z/J4/Gob9++Ki8vdx2zcuVKdevWTR6PRwMGDJDjOCF9DgwgAACAyFd6rEH9ElONEvCJDzbbjgUA6AD2b0gUgFGpV69euuuuuzRr1iytXbtWeXl5WrRokR5++OHgi7p3797Kz89v9RwLFy7UeeedF7wYyIwZM7Rp0yatWbNGiYmJ+vKXvyyPx6Pu3bsrJycn5M+BAQQAABAdnk/e6foocN6B47ZjAQDaif0bEgVgVOrZs2fwxdvS7dprr22z/PvC9OnT1aNHj1bP89WvflVLliwJy3NgAAEAAESH6gafvvncMqMAfHBGTsg/IQIACA/2b0gUgFFpwYIFGjp0qK677jp9/etfV48ePdSnTx/dfffdeuedd+Tz+dp9rh07dmj48OG68sor9eUvf1lf/epXNXDgQP3pT3/SkSNHwvYcGEAAAADR4501+1zvAvx822HbsQAA7cD+DYkCEJYwgAAAAKKHtzmg70/JMgrA776QqaZmv+1oAICzYP+GRAEISxhAAAAA0SWt4IjrXYB/Wb3XdiwAwFmwf0OiAIQlDCAAAIDo4jiOfjoz1ygArx+frhP1XtvRAABtYP+GRAEISxhAAAAA0Se/9ITrXYDPLt1hOxYAoA3s35AoAGEJAwgAACA6PTU/3ygArxiVon1V9bZjAQBawf4NiQIQljCAAAAAotPB4w3ql5hqlICPz8mzHQsA0Ar2b0gUgLCEAQQAABC9JqXscn0UeOP+47ZjAQBawP4NiQIQljCAAAAAolf1KZ++9dwyowC8f3qOAgHHdjQAwBnYvyFRAMISBhAAAEB0ey9nn+tdgJ9tPWw7FgDgDOzfkCgAYQkDCAAAILr5/AH9r6krjQLw1smZavT5bUcDAJyG/RsSBSAsYQABAABEv/QdR13vAnxz1R7bsQAAp2H/hkQBCEsYQAAAANHPcRwNeXOtUQAOGJ+u4/Ve29EAAH/D/g2JAhCWMIAAAABiw7ayk653AY7/bIftWACAv2H/hkQBCEsYQAAAALHjdwvyjQLwilEp2ltZZztWRKpu8Olns9ap/5hUPTA9R39ZvVdlJxpsxwIQw9i/IVEAwhIGEAAAQOwoO9GgfqNTjRLwV7M32Y4VkUYu3uZ6x2TfEcm6f3qO3lq9RwePUwYCCC32b0gUgLCEAQQAABBb/pxW6Cq11u09ZjtWRKmqa3IVpS3d7pu2RjNXUQYCCA32b0gUgLCEAQQAABBbahp9+vaE5a4iKxBwbEeLGK9mFJ+1/Dvzdu/ra/TGyj0qPUYZCKBz2L8hUQDCEgYQAABA7Jmzdr+rwPo0/5DtWBGhqdmvQUkZxt/m9hdX6pvPLWt3Gfij17M1Y2WJDhyrt/10AEQR9m9IFICwhAEEAAAQe3z+gG5/caVRWt06OVONPr/taNZ9tOmgq9DbebhGPn9Aq3dXasSibfpWB8rAu1/N1vSsEu2rogwE0Db2b0gUgLCEAQQAABCbMnaWu8qqGStLbMeyynEc/fCV1cbf5D/fWuc6zucPKLu4UiMXb3N9nLqt2+BXszUts5grLwNoEfs3JApAWMIAAgAAiE2O4+jht9YaBdV149J1rK7JdjRrckqqXKXdil3lbf5Osz+gNcVVGvXJdn2nA2XgD19ZrddXFGsPZSCAv2H/hkQBCEsYQAAAALGr4FC1q5ga82mB7VjWDH1vo/ndf1NXdujiKM3+gHJLqpT4yXYNSmp/GXjXy6v1akaxSipqw/jsAEQ69m9IFICwhAEEAAAQ236/cItRRl0+KkUlFfH3rrQ9lXWuYm7O2v2dPp8/4Ch3T5VGf7rddVGRtm4/eHmVXsnYreJyykAg3rB/Q6IAhCUMIAAAgNh2+OQpXTU61SihHnt/o+1YXW70p9uNv8HAZ5epwdscknP7A47W7jmmMZ8WdKgM/Pnb61XfFJoMACIf+zckCkBYwgACAACIfVPSC13lU+6eKtuxuszJBq+uHpNmPP/JqYVheSx/wNH6vcc0bkmBbnz+7GXg9Kz4vjALEE/YvyFRAMISBhAAAEDsq2tqdn1n3Y9ez+7Q999FsxkrS4znfsWoFB2pPhX2xw0EHG3Yd1zjP9uhmya2XAb+6PXssOcAEBnYvyFRAMISBhAAAEB8mLvugKt8Wrw59v/9520OuMq3p+fnd3mOQMDRxv3H9aePt7n+fzha3djleQB0PfZvSBSAsIQBBAAAEB+a/QHd+dIqo3j690krdMrrtx0trD7NP+Qq3LaVnbSWx+cPaMD4dCPPvPWl1vIA6Drs35AoAGEJAwgAACB+ZBaWx9V30DmOo3tfX2M835/OzLUdS0/Nzzcy/b/34u+iLEA8Yv+GRAEISxhAAAAA8cNxHP1s1jqjfLp2bJoqa5tsRwuLDfuOuwrPtIIjtmNpyRbzXYlXjU6N+XdiAmD/xl9RAMIKBhAAAEB82XG4WpeONEuxxE+2244VFr+es8l4nt99IVP+CLjwyckGry4flWJky9hZbjsWgDBj/4ZEAQhLGEAAAADx5w8fbTXKp8tGJqu4vNZ2rJAqPdbgKjrfXrPPdqygIW+uNbKNXBybJSyAv2P/hkQBCEsYQAAAAPHnaHWj+o9JNQqooTH2PXTPLt1hPL/rxqWrttFnO1bQW6v3GPlumpghx7H/7kQA4cP+DYkCEJYwgAAAAOLTS8uKXN+Pl1NSZTtWSNQ0+nTt2DTjuSV9vtN2LMOeyjrX3397WbXtWADCiP0bEgUgLGEAAQAAxKe6pmYNSsowCqjBr2ZHxHfknau/rN7r+ojzweMNtmMZHMfR96dkGTlfydhtOxaAMGL/hkQBCEsYQAAAAPFr/oZS17vQPtp00Hasc9LsD+jWyZnGcxr+QZ7tWC2a8PlOI+e9r6+xHQlAGLF/Q6IAhCUMIAAAgPjV7A/oBy+vcn0XXYO32Xa0TkvedsRVauYdOG47Voty91S5spbXNNqOBSBM2L8hUQDCEgYQAABAfFtZVOEqoV5bUWw7Vqf9eEaO8Vzun54TsRfX8PkDGjA+3cg7b32p7VgAwoT9GxIFICxhAAEAAMQ3x3H087fXGyXUNWPTdKT6lO1oHba59ISrzPxs62Hbsdr05LzNRt7H3o+tqzED+Dv2b0gUgLCEAQQAAIBdR2p06UizOPv52+sViLILgjxxRpn275NWyOcP2I7Vpk/zDxmZ+49JVaPPbzsWgDBg/4ZEAQhLGEAAAACQpD99vM317rn3c/fbjtVuh06e0uWjUoz8b67aYzvWWZ1s8OqyM8rXFbvKbccCEAbs35AoAGEJAwgAAACSVN3g080TVxhF1FWjU1VSUWc7WrtMTNnl+hhz9Smf7VjtMmTmWiP7qE+2244EIAzYvyFRAMISBhAAAAC+kF1c6XoX4H3T1kT8x2jrm5pdF9MYt6TAdqx2e3PVHiP7zRNXROyFSwB0Hvs3JApAWMIAAgAAwOnGf7bDVQK+vHy37Vhtei9nn5H30pHJ2l9VbztWu5VU1Ln+5gWHqm3HAhBi7N+QKABhCQMIAAAApzvl9ev2F1caZdTlo1K05eBJ29Fa5A84um1K1hlX0t1kO1aHOI6j75/xHF7JiOzSFUDHsX9DogCEJQwgAAAAnGnrwZOuC2rcPnWlTnkj7+q0y3Ycdb17bu2eY7ZjddhzS3e6PnoNILawf0OiAIQlDCAAAAC05JWM3a5ibWwEfq/ekDfNC2jc81p2VH5/Xm5JlevvXV7TaDsWgBBi/4ZEAQhLGEAAAABoic8f0P3Tc1yl1OrdlbajBRUcqnblW7w5Ov9N6/MHNGCceSGT+RtKbccCEELs35AoAGEJAwgAAACt2VtZp/5jUo1S6qaJGTrZ4LUdTZL03wu3GNlufD5D3ubIvmJxW56Yt/mM7zLcaDsSgBBi/4ZEAQhLGEAAAABoy+y1+13vsntqfr7tWCqvadQVZ3xP4bTMYtuxzskn+WXG8+k/JlWNvsj73kUAncP+DYkCEJYwgAAAANAWx3H087fXu0rAJVsOWc01Jb3QyHPV6FQdr4+MdyZ21ol6ry4baf6dMwvLbccCECLs35AoAGEJAwgAAABnc7S6UQOfXWYUU9ePT9eR6lNW8pzy+vXN58w8Ixdvt5Il1IbMNC9qMuqT2HheANi/8VcUgLCCAQQAAID2WLr1sOtdgD9/e70Cga6/4u4H6w+4spRU1HZ5jnCYuWqP8bxunrgiKq9qDMCN/RsSBSAsYQABAACgvZ6en+8q3t7P3d+lGQIBR7e/uNLI8F/vbujSDOFUUlHr+hsXHKq2HQtACLB/Q6IAhCUMIAAAALRXdYNPN09c4fruvZKKui7LkFVY4SrIsosru+zxw81xHN02Jct4fq9mRPfFTQD8Ffs3JApAWMIAAgAAQEdkF1e6Crj7pq2Rzx/oksd/dJZ5QZK7Xl4dcx+RfW7pTtffF0D0Y/+GRAEISxhAAAAA6Kjxn+1wlYAvL98d9sctPFrjetyFG0vD/rhdLaekyvU8K2oabccCcI7YvyFRAMISBhAAAAA66pTX7/oevstHpWjLwZNhfdz/+Xir8ZjfmbBcjT5/WB/TBm9zQAPGpRvPdcGG2Cs6gXjD/g2JAhCWMIAAAADQGVsPntTlo1KMkur2qSt1yhueQq6ytkn9Rqcaj/dSF7zr0JYn5m02nutj72+yHQnAOWL/hkQBCEsYQAAAAOisVzOKXR9VHbukICyP9fLy3cbj9EtMVWVtU1geKxIs3lxmPN+rx6TF5LsdgXjC/g2JAhCWMIAAAADQWc3+gO6fnuMqAVfvDu1VeRt9fn1nwnLjMf740daQPkakOVHv1WUjzb9rVmGF7VgAzgH7NyQKQFjCAAIAAMC52FtZp/5jzI/m3jQxQycbvCF7jA83HnSVjIVHa0J2/kj105m5xnNO/GS77UgAzgH7NyQKQFjCAAIAAMC5mr12v6uge2p+fkjO7TiOfvjKauPcP5u1LiTnjnQzV+0xnve/T1ohx3FsxwLQSezfkCgAYQkDCAAAAOfKcRz94p0NrhJwyZZD53zuNcVVrvNmFpaHIHXkKy6vdT33HYerbccC0Ens35AoAGEJAwgAAAChUF7TqIHPLjPKquvHp+tI9alzOu8v3zWLxdtfXKlAID7eBec4jr73Qpbx/F9bUWw7FoBOYv+GRAEISxhAAAAACJWlWw+73rH287fXd7qwK6moc51vzroDIU4d2Z5dusN4/vdPW2M7EoBOYv+GRAEISxhAAAAACKWn5+e7Srv3c/d36lyjPtlunOebzy1Tg7c5tIEjXEsfga6obbQdC0AnsH9DogCEJQwgAAAAhFJ1g083T1xhFFZXjU5VSUVdh85zot7rurrwC2mFYUodubzNAQ0Yl278HRZuLLUdC0AnsH9DogCEJQwgAAAAhFpL71q7b9oa+fyBdp9jelaJ8ftXjErR0er4fOfbEx9sNv4Ww2Zvsh0JQCewf0OiAIQlDCAAAACEw/jPdrhKwJeX727X73qbA7rx+Qzjd3+3ID/MiSPX4s1lxt/i6jFpavT5bccC0EHs35AoAGEJAwgAAADhcMrr1x0vrjSKq8tHpWjLwZNn/d1P8stc5eH2suouSB2Zjtd7ddlI8++RVVRhOxaADmL/hkQBCEsYQAAAAAiXbWUndcWoFKO4un3qSp3ytv7uNcdx9KPXs43fGTJzbRemjkw/eSPX+JuM/nS77UgAOoj9GxIFICxhAAEAACCcXs0odr2bb+ySglaPX7/3mOv49B1HuzBxZHpj5R7jb3LLpBVyHMd2LAAdwP4NiQIQljCAAAAAEE7N/oDun57jKvVW765s8fhhszcZx33vhSz5AxRdxeW1rr/hzsM1tmMB6AD2b0gUgLCEAQQAAIBw21tZp/5jUo3y6qaJGTrZ4DWO219Vr0vP+K67d3P2WUodWRzH0XdfyDT+Nq+vKLYdC0AHsH9DogCEJQwgAAAAdIU5a/e73sH21Hzzyr5nXjl4wLh01TU1W0ocec78+9w/Pcd2JAAdwP4NiQIQljCAAAAA0BUcx9Ev3tngKgGXbDkkSao+5dM1Y9OM+55P3mk5dWRZU1zl+vtV1DbajgWgndi/IVEAwhIGEAAAALpKeU2jBj67zCiwrh+friPVp/TWavMiF5eNTFbZiQbbkSOKtzmg68alG3+nDzcetB0LQDuxf0OiAIQlDCAAAAB0pc+3HXa9i+3RWet162Tz++2e+GCz7agRafgHecbf6VezN9mOBKCd2L8hUQDCEgYQAAAAutpvF+S7SsAzb5tLT9iOGZEW5ZUZf6erx6Sp0ee3HQtAO7B/Q6IAhCUMIAAAAHS16gafbp64otXy78EZXNyiNcfrva4rJWcVVdiOBaAd2L8hUQDCEgYQAAAAbGjpghZf3D7fdth2vIj20Bu5xt9rzKcFtiMBaAf2b0gUgLCEAQQAAABbxn+2w1X+3To5U83+gO1oEW3GyhLjb3bLpBVyHMd2LABnwf4NiQIQljCAAAAAYEujz687XlxplFlvrd5jO1bE211e6ypOdx6usR0LwFmwf0OiAIQlDCAAAADYVFxeG7wC8C/e2aCmZi5ocTaO4+i7L5hXTZ6WWWw7FoCzYP+GRAEISxhAAAAAsC0QcFRV12Q7RlQ58+PTD0znwilApGP/hkQBCEsYQAAAAED0yS6uNArAS0cmq7KWEhWIZOzfkCgAYQkDCAAAAIg+3uaArh2bZpSAH248aDsWgDawf0OiAIQlDCAAAAAgOv1mbp5RAP56zibbkQC0gf0bEgUgLGEAAQAAANHp47wyowC8ZmyaGn1cRAWIVOzfkCgAYQkDCAAAAIhOx+qadOnIZKMEXFlUYTsWgFawf0OiAIQlDCAAAAAgej30Rq5RAI5dUmA7EoBWsH9DogCMWo2NjZoxY4buuOMOXXjhhUpISNDFF1+se+65RwsXLuzUORsaGnTZZZcFB0Pfvn1DG/o0DCAAAAAgek3PKjEKwFsnZ8pxHNuxALSA/RsSBWBUKioqUv/+/YMv4JZugwcPVn19fYfO+4c//ME4BwUgAAAAgJYUHa01CsC+I5K160iN7VgAWsD+DYkCMOpUVlbqkksuCb54hwwZouTkZOXn5ys5OVlDhgwJ3nffffe1+7z5+fnq1q2bvvSlL6lXr14UgAAAAABa5TiO/uPPmUYBOC2z2HYsAC1g/4ZEARh1nnzyyeALd/z48S0eM27cuOAxixcvPus5/X6/Bg0aJI/HowkTJqhv374UgAAAAADaNG5JgVEAPjgjx3YkAC1g/4ZEARhV/H6/LrjggmA55/f7Wz3uG9/4hjwej2644Yaznvell16Sx+NR//795fV6KQABAAAAnNXq3ZVGAXjpyGRV1TXZjgXgDOzfkCgAo0phYWHwRTts2LA2j33ssceCx+7fv7/V4w4cOKCePXvK4/EoKytLkigAAQAAAJxVU7Nf145NM0rADzcdtB0LwBnYvyFRAEaV3Nzc4It29OjRbR6bmJgYPHb27NmtHnfPPffI4/HoF7/4RfBnFIAAAAAA2uM3c/OMAvDxOXm2IwE4A/s3JArAqLJ169bgi/app55q89jTvytwxIgRLR6zYMECeTwe9e7dWxUVFcGfUwACAAAAaI+PNh00CsBrx6apqbnlryoCYAf7NyQKwKhSX1+vhIQEeTweDRw4sM1jr7/++uAL/JFHHnHdf+LECf3zP/+zPB6P3nrrLeO+UBSAZWVlbd42btzIAAIAAACiXFVdky4dmWyUgKt2V9qOBeA0FICQKACjzuDBg4Mv3Pnz57d4zPz584PHeDwe3Xvvva5jvviOwFtuuUWO4xj3haIAPP3xz3ZjAAEAAADR68czcowCcOySAtuRAJyGAhASBWDU2bBhg7p37y6Px6OEhAQlJSWptLRUPp9PpaWlSkpKUkJCgnr06BF8gd95553GOVavXq3zzjtP3bt317Zt21yPQQEIAAAAoL2mZ5UYBeCtkzNdbzIAYA8FICQKwKg0e/Zso+A789atWzdNmzYt+L8ffPDB4O82NTWpf//+8ng8+sMf/tDi+fkIMAAAAID2KjxaYxSAfUckq/Boje1YAP6GAhASBWDU2rp1q4YMGaJevXoFX8jnn3++7rzzTq1fv14FBQXBnw8dOjT4e2PHjpXH49Ell1yiurq6Fs/NRUAAAAAAtJfjOLp1cqZRAE7PKrEdC8DfsH9DogCMen6/X2VlZSopKVFDQ0Pw5/PmzQu+wKdOnRr8+RfvHBw6dKgWLFjQ4u3CCy+Ux+PRhRdeGPxZZmZmSHMzgAAAAIDYMW5JgVEAPjgjx3YkAH/D/g2JAjBmDR8+PPgCz87ODv68I9/Nd/rt+9//fkjzMYAAAACA2LFqd6VRAF46MllVdU22YwEQ+zf+igIwBnm9Xl100UXyeDzq06eP/H5/8D4KQAAAAACh1tTs17Vj04wS8KNNB23HAiD2b/wVBWAMmjJlSvDFnZSU1OHf5zsAAQAAAHTU43PyjALw8Tl5tiMBEPs3/ooCMAqVlpa2et/SpUuVkJAgj8ejfv36qbGxscPnpwAEAAAA0FEfbTpoFIDXjk1TU7P/7L8IIKzYvyFRAEalXr166a677tKsWbO0du1a5eXladGiRXr44YeDL+revXsrPz+/U+enAAQAAADQUVV1Tbp0ZLJRAq7eXWk7FhD32L8hUQBGpZ49e7b5fX3XXnttp8s/iQIQAAAAQOc8OCPHKADHLSmwHQmIe+zfkCgAo9KCBQs0dOhQXXfddfr617+uHj16qE+fPrr77rv1zjvvyOfzndP5KQABAAAAdMb0rBKjALx1cqYcx7EdC4hr7N+QKABhCQMIAAAAiD27jtQYBWDfEckqOlprOxYQ19i/IVEAwhIGEAAAABB7HMfRrZMzjQJwelaJ7VhAXGP/hkQBCEsYQAAAAEBsGrukwCgAfzwjx3YkIK6xf0OiAIQlDCAAAAAgNq3aXWkUgJeOTNaxuibbsYC4xf4NiQIQljCAAAAAgNjU6PPrmrFpRgn4cR7/5gdsYf+GRAEISxhAAAAAQOz69ZxNRgH4m7l5tiMBcYv9GxIFICxhAAEAAACx68NNB40C8NqxaWpq9tuOBcQl9m9IFICwhAEEAAAAxK7K2iZdOjLZKAGziyttxwLiEvs3JApAWMIAAgAAAGLbA9NzjAJw/Gc7bEcC4hL7NyQKQFjCAAIAAABi27TMYqMA/I8/Z8pxHNuxgLjD/g2JAhCWMIAAAACA2LbrSI1RAPYdkazd5bW2YwFxh/0bEgUgLGEAAQAAALHNcRzdMmmFUQDOWFliOxYQd9i/IVEAwhIGEAAAABD7xnxaYBSAD72RazsSEHfYvyFRAMISBhAAAAAQ+1YWVRgF4KUjk1VV12Q7FhBX2L8hUQDCEgYQAAAAEPsafX5dMzbNKAE/2nTQdiwgrrB/Q6IAhCUMIAAAACA+PD4nzygAH5+TZzsSEFfYvyFRAMISBhAAAAAQHz7adNAoAK8Zm6ZGn992LCBusH9DogCEJQwgAAAAID5U1TXp0pHJRgm4sqjCdiwgbrB/Q6IAhCUMIAAAACB+/HhGjlEAjvm0wHYkIG6wf0OiAIQlDCAAAAAgfsxYWWIUgLdMWiHHcWzHAuIC+zckCkBYwgACAAAA4sfu8lqjAOw7Ilk7D9fYjgXEBfZvSBSAsIQBBAAAAMQPx3H03RcyjQLw9RXFtmMBcYH9GxIFICxhAAEAAADxZfxnO4wC8P5pa2xHAuIC+zckCkBYwgACAAAA4ktOSZXrY8AVNY22YwExj/0bEgUgLGEAAQAAAPHF2xzQgHHpRgG4YEOp7VhAzGP/hkQBCEsYQAAAAED8eWLeZqMAfOz9TbYjATGP/RsSBSAsYQABAAAA8eeT/DKjAOw/JlWNPr/tWEBMY/+GRAEISxhAAAAAQPw52eDV5aNSjBJwxa5y27GAmMb+DYkCEJYwgAAAAID4NOTNtUYBOHLxdtuRgJjG/g2JAhCWMIAAAACA+PTW6j1GAXjTxAwFAo7tWEDMYv+GRAEISxhAAAAAQHzaU1lnFIB9RyRrW9lJ27GAmMX+DYkCEJYwgAAAAID4dfvUlUYB+NLy3bYjATGL/RsSBSAsYQABAAAA8ev55J1GAXjPa9m2IwExi/0bEgUgLGEAAQAAAPFr3d5jro8BH6k+ZTsWEJPYvyFRAMISBhAAAAAQv5r9AQ18dplRAM5Zd8B2LCAmsX9DogCEJQwgAAAAIL79bkG+UQD+17sbbEcCYhL7NyQKQFjCAAIAAADi29Kth40CsN/oVDV4m23HAmIO+zckCkBYwgACAAAA4ltNo09XjEoxSsD0HUdtxwJiDvs3JApAWMIAAgAAAPDIX9YZBeAfP9pqOxIQc9i/IVEAwhIGEAAAAIB31uwzCsBBScsVCDi2YwExhf0bEgUgLGEAAQAAACg91mAUgH1HJGtz6QnbsYCYwv4NiQIQljCAAAAAAEjS/35plVEATkkvtB0JiCns35AoAGEJAwgAAACAJE1OLTQKwLteXm07EhBT2L8hUQDCEgYQAAAAAEnatP+462PAB4832I4FxAz2b0gUgLCEAQQAAABAkvwBR9+esNwoAN/L2Wc7FhAz2L8hUQDCEgYQAAAAgC888+FWowD8+dvrbUcCYgb7NyQKQFjCAAIAAADwhdTtR4wC8MrEFNU2+mzHAmIC+zckCkBYwgACAJfJ578AACAASURBVAAA8IW6pmb1S0w1SsDkbUdsxwJiAvs3JApAWMIAAgAAAHC6X7yzwSgAf79wi+1IQExg/4ZEAQhLGEAAAAAATjd77X6jAPzWc8vU7A/YjgVEPfZvSBSAsIQBBAAAAOB0ZScajAKw74hkbdh33HYsIOqxf0OiAIQlDCAAAAAAZ/rhK6uNAnBSyi7bkYCox/4NiQIQljCAAAAAAJzpxWVFRgF4x4srbUcCoh77NyQKQFjCAAIAAABwpi0HT7o+Bry/qt52LCCqsX9DogCEJQwgAAAAAGcKBBzd8HyGUQDOyt5rOxYQ1di/IVEAwhIGEAAAAICW/OnjbUYB+PBba21HAqIa+zckCkBYwgACAAAA0JLlO8uNAvDyUSmqbvDZjgVELfZvSBSAsIQBBAAAAKAlp7x+XTU61SgBl2w5ZDsWELXYvyFRAMISBhAAAACA1gx9b6NRAD49P992JCBqsX9DogCEJQwgAAAAAK35YP0BowAcMD5dPn/AdiwgKrF/Q6IAhCUMIAAAAACtOVrdaBSAfUckK3dPle1YQFRi/4ZEAQhLGEAAAAAA2nLv62uMAnDC5zttRwKiEvs3JApAWMIAAgAAANCWVzJ2GwXgbVOy5DiO7VhA1GH/hkQBCEsYQAAAAADaUnCo2vUx4JKKWtuxgKjD/g2JAhCWMIAAAAAAtMVxHN08cYVRAM5ctcd2LCDqsH9DogCEJQwgAAAAAGeT+Ml2owD86cxc25GAqMP+DYkCEJYwgAAAAACcTVZhhVEAXjYyWcfrvbZjAVGF/RsSBSAsYQABAAAAOJtGn19Xj0kzSsBFeewPQEewf0OiAIQlDCAAAAAA7fGr2ZuMAnD4B3m2IwFRhf0bEgUgLGEAAQAAAGiPDzceNArA68aly9scsB0LiBrs35AoAGEJAwgAAABAe1TWNunSkclGCZhdXGk7FhA12L8hUQDCEgYQAAAAgPZ6YHqOUQCOW1JgOxIQNdi/IVEAwhIGEAAAAID2mp5VYhSAt07OlOM4tmMBUYH9GxIFICxhAAEAAABor8KjNUYB2HdEsgqP1tiOBUQF9m9IFICwhAEEAAAAoL0cx9GtkzONAnB6VontWEBUYP+GRAEISxhAAAAAADpi3JICowB8YHqO7UhAVGD/hkQBCEsYQAAAAAA6Iru40igALx2ZrMraJtuxgIjH/g2JAhCWMIAAAAAAdIS3OaDrxqUbJeCHGw/ajgVEPPZvSBSAsIQBBAAAAKCjhn+QZxSAv5q9yXYkIOKxf0OiAIQlDCAAAAAAHbUor8woAK8ek6ZGn992LCCisX9DogCEJQwgAAAAAB11vN6ry0YmGyVgVmGF7VhARGP/hkQBCEsYQAAAAAA646czc40CMPGT7bYjARGN/RsSBSAsYQABAAAA/7+9ew+3sqzzx7/UDTWgjXjqGtAoUSBNi5EOU5NO2jikmWEXOX5/U/5M0/FQTWXDKWEUxRQPmZb2dRyGSsBQU9mcRQmErRtCFA8oJxEPHFQQ2GzY7L0/vz/88cRi7TNr7Wevxet1Xfcf7XWvZ33W5b0+eb+913poi7vnrMgKAD9/w+NRX1+fdlnQYdl/EyEAJCUaEAAA0BbL12/JCgB7Di6PpW9sTrss6LDsv4kQAJISDQgAAGiL+vr6OPXmJ7ICwNtnvZJ2WdBh2X8TIQAkJRoQAADQVtdNfjErAPz6r+alXRJ0WPbfRAgASYkGBAAAtNX8FRtzvga87v3qtMuCDsn+mwgBICnRgAAAgLaqqa2LT42cnhUA3v/0mrTLgg7J/psIASAp0YAAAIB9cdX4xVkB4EVjK9MuCTok+28iBICkRAMCAAD2xSPPvpEVAPYePjW276xNuyzocOy/iRAAkhINCAAA2Bebq2ri2KFTskLAmS+uS7ss6HDsv4kQAJISDQgAANhX5/92QVYAOPjB59IuCToc+28iBIBFq7q6On7961/H6aefHkcccUR06tQpunfvHmeddVZMnDix2ec+8sgjcdVVV8XnPve56NatW5SVlUW3bt3iC1/4QowcOTLeeuutgtavAQEAAPvq3rkrswLAU0bNirq6+rTLgg7F/psIAWBRWrZsWfTp0yf5ADc0BgwYENu2bct57nPPPReHHHJIk8/NZDJxyCGHxAMPPFCw96ABAQAA+2rVxm1ZAWDPweXx7Oub0i4LOhT7byIEgEVnw4YNccwxxyQf3kGDBkV5eXksXrw4ysvLY9CgQclj55xzTs7z582blzz+pS99KW688caYNWtWLF68OGbMmBGXXXZZHHTQQZHJZOKggw6KqVOnFuR9aEAAAEA+nH7Lk1kB4C0zlqVdEnQo9t9ECACLzpVXXpl8cEeOHNngnBEjRiRzHnrooazH5s+fH9/+9rfjxRdfbPQ1HnnkkTjggAMik8lEr169or4+/0foNSAAACAfRk95KSsAHPDLuWmXBB2K/TcRAsCiUltbG4ceemhkMpno2bNn1NY2fIv72tra+NjHPhaZTCb69+/fptf61re+lTSIxYsX70vZDdKAAACAfHhm1bs5XwNe+15V2mVBh2H/TYQAsKi8/PLLyYf2kksuaXLuxRdfnMxdvXp1q1/rrrvuSp4/adKkNlbcOA0IAADIh121dfGZa2dkBYDjFqxOuyzoMOy/iRAAFpX58+cnH9rhw4c3OXfYsGHJ3HHjxrX6tW699dZGv0acDxoQAACQLz+e+GxWAPid+55JuyToMOy/iRAAFpUlS5YkH9qrrrqqybl7/lbg4MGDW/1a3/jGN5LnN/V7gW2lAQEAAPlS/txbWQHg8cOmxtYdu9IuCzoE+28iBIBFZdu2bdGpU6fIZDJx8sknNzn3pJNOSj7gF1xwQateZ8mSJcmdgE888cQ21bp27domR2VlpQYEAADkxZbqmjhu2JSsEHDq82+lXRZ0CAJAIgSARWfAgAHJB3f8+PENzhk/fnwyJ5PJxNe//vUWX3/Hjh3Rv3//5LmPPvpom+rc8/WbGxoQAACwr/7tv5/OCgB/8sCStEuCDkEASIQAsOg888wzUVZWFplMJjp16hSjRo2KNWvWRE1NTaxZsyZGjRoVnTp1is6dOycf8DPOOKPF17/kkkuS51144YVtrlMACAAAtKexT63KCgD7XTczauvq2+3136+uicdfWhejJr8Y//bfT8cNU16K6pradnt9aIwAkAgBYFEaN25cVsC39zjooIPizjvvTP73N7/5zRZdd/To0clzTjnllNi2bVuba/QVYAAAoD29/m5VVgDYc3B5LHrt3YK93rYdu2LOKxti9NSX4ht3zotPDCnPef2Rj75QsNeHlhIAEiEALFpLliyJQYMGxSGHHJJ8kA888MA444wz4umnn46lS5cmf7/ooouavd4999yTzO/Tp09s2LChoPVrQAAAQL6dedufswK4G6e+nLdrV9fUxlPLN8aY6cvivN/Mj15Dp+QEfnuP44ZNibXvVeWtBmgL+28iBIBFr7a2NtauXRvLly+Pqqq//h/L/fffn3zAx4wZ0+Q1xo8fHwceeGBkMpno2bNnuzQEDQgAAMi3m6e/nBXAffXWOW2+1o5dtfH0ynfi9lmvxLfvWRDHD5vabODX0Bj68PN5fIfQevbfRAgAS9bll1+efMDnzp3b6LxHH300+U3Bv/u7v4sVK1a0S30aEAAAkG9/WfNeTgC35p2WncCrqa2LRa+9F3c9sTz+n3ufjj4/b33gd/ywqfHFG2c7BUiHYv9NhACwJO3cuTOOPPLIyGQy0aNHj6itbfiHZx9//PH40Ic+FJlMJg4//PB44YX2+30KDQgAAMi3urr6OGXUzKwA7r55qxqcW1tXH8+t3RR3z1kR373vmTjhmmmtDvx6DZ0S5/1mfoyZviyeWr4xqmtqY9371XH88OzwcMhDTgGSHvtvIgSAJenmm29OPtyjRo1qcM78+fOja9eukclk4iMf+UgsWrSoXWvUgAAAgEK4+o9LssK3C/5vRUR8EA6+8ObmuHfuyrj4fyvjUyOntzrw+8SQ8vjGnfNi9NSXYs4rG2Lbjl0N1jDy0RdygkKnAEmL/TcRAsCitGbNmkYfe+yxx6JTp06RyWTi+OOPj+rq6pw5zz77bBx66KGRyWSia9eu8dRTTxWy3AZpQAAAQCFMf+HtnPDtst8tis9cO6PVgd/Hh5TH1345N66b/GI8/tK6eL+6pkU1rH+/Ono7BUgHYf9NhACwKB1yyCFx5plnxr333hsLFiyIRYsWxYMPPhjnn39+8qHu1q1bLF68OOe5K1asiKOOOiqZd/vtt8fSpUubHOvXr8/7e9CAAACAQqjauSvnK7itGf9825wY+egLMW3p27Gpameb6/ivx3JPAb7+rlOAtD/7byIEgEVp91d3GxsnnHBCg+FfRMTYsWObfG5DY+TIkXl/DxoQAABQKBf+zzMtDvy+csuTMezh52Pyc2/Gxq078lZDw6cAn8vb9aGl7L+JEAAWpQkTJsRFF10UJ554Yhx22GHRuXPn6NGjR3zta1+L++67L2pqGj+WLgAEAABK3QMLX2808PvyTU/Ef056Lv60+I1Y937uTybl07WPvegUIKmz/yZCAEhKNCAAAKBQdtXWxY8mLI7jhk2Jfxj9ePz4gWfjjwtfb/cbcTR0CnDwg04B0r7sv4kQAJISDQgAANgfXDfZKUDSZf9NhACQlGhAAADA/mD9ltxTgP85ySlA2o/9NxECQFKiAQEAAPuLhk4BrnnHKUDah/03EQJAUqIBAQAA+4v1W6qjz8+dAiQd9t9ECABJiQYEAADsT0btdQrwWKcAaSf230QIAEmJBgQAAOxPNmzZkXMK8GeTlqRdFvsB+28iBICkRAMCAAD2N9eXOwVI+7P/JkIASEo0IAAAYH/T0CnAq//oFCCFZf9NhACQlGhAAADA/qihU4CvvbMt7bIoYfbfRAgASYkGBAAA7I82bnUKkPZl/02EAJCUaEAAAMD+6oYpL+WcAly90SlACsP+mwgBICnRgAAAgP3Vxq07ou/Pp2WFgD91CpACsf8mQgBISjQgAABgfza6RE4BvrFpe9w07eX4w9OvRV1dfdrl0AD7byIEgKREAwIAAPZnDZ0C/MkDxXUK8MU3348Trvnrexg1+cW0S6IB9t9ECABJiQYEAADs74r5FOD6LdXxD6Mfz6q/19Ap8fbm6rRLYy/230QIAEmJBgQAAOzv3mngFOCPH3g27bKaVV1TG9+466msunePX0x7Oe3y2Iv9NxECQFKiAQEAAESMnpp9CvATQ8pjVQc+BVhfXx9XjV/cYPjXc3B5nPxfM6Jq5660y2QP9t9ECABJiQYEAADwwSnAT15TPKcAb5/1SqPh3+7xuwWr0y6TPdh/EyEAJCUaEAAAwAdunPpyzinAlRu2pl1WjseWvJkT9p04Ynp84855WX/7pzFPuiNwB2L/TYQAkJRoQAAAAB94d9vO3FOAEzvWKcBnX98UvYdPzQkqn1y2Pp5avjEnGHz8pXVpl8z/z/6bCAEgKdGAAAAA/uoX0zruKcA3N22PU0bNygn5/uepVRHxwe8C/svtf8567F9/W5Fy1exm/02EAJCUaEAAAAB/1dApwP/oAKcAt+3YFQN+OTcn/Bv28PNRX//Xr/n+ceHrOXNeeHNzipWzm/03EQJAUqIBAQAAZGvoFOCKFE8B1tXVx/fHLcwJ9v7PvRVRU1uXNXfHrtqcU4I/eWBJSpWzJ/tvIgSApEQDAgAAyPbutp1xQgc6Bbj3zUl6Di6Pr4x5MjZX1TQ4/47HX82ae9ywKbH+/ep2rpq92X8TIQAkJRoQAABArps6yCnAhr7Se/J/zYhVG7c1+px3tu6I4/e6UcgtM5a1Y9U0xP6bCAEgKdGAAAAAcr3XwCnAH01Y3K41PLPq3Thu2JSsGnoNnRLzV2xs9rmDH3wu63n9rpsZ1TW17VA1jbH/JkIASEo0IAAAgIbdPD33FODy9e1zCnDNO1XxmWtn5Jz+G//MmhY9/5V1W9r8XArD/psIASAp0YAAAAAa1tApwB+2wynA96tr4oxb5+QEeNdNfrFV1/nOfc9kPf+MW+dk3TGY9mX/TYQAkJRoQAAAAI3b+xTgxwt8CnBXbV1OcNdzcHlcNLYyautaF97NeWVDznWeXLa+QJXTHPtvIgSApEQDAgAAaNx723bGiSOmZ4VoPxhfuFOAIx99ISe0O/O2P8eW6obv+NuU+vr6+OpeJwn/7b+fLkDVtIT9NxECQFKiAQEAADRtzPRlDZwC3JL31/ldxWs54d/fXzczXn+3qs3XnPDMmpxrLns7/7XTPPtvIgSApEQDAgAAaNqmqsKfApz76oY4dmj2HX+PHzY1Fr327j5dt7qmNvpdNzPruv856bk8VU1r2H8TIQAkJRoQAABA826ZkXsK8NV1+TlJt3z91vjUyOk5J/X+tPiNvFz/1r1qP3741Ni4dUderk3L2X8TIQAkJRoQAABA8xo6BXhVHk4BvrdtZ5x68xM54d+Y6cvyUPUH1m+pjuOHTc26/i9nvZq369My9t9ECABJiQYEAADQMvk+BbhzV118+54FOeHfv/9+UdS18o6/zfnpH5dkvcYpo2ZGdU1tXl+Dptl/EyEAJCUaEAAAQMtsqtoZn9rrFOCV9/+lTdeqr6+P/5z0XE74d/av5kbVzl15rjzixTffz3mtBxa+nvfXoXH230QIAEmJBgQAANBye/+e3seHlMcrbTgFeO/clTmB3OdumBVvb64uQNUf+D/3VmS93r/c/ueor8/vSUMaZ/9NhACQlGhAAAAALbe5qmafTwE+/tK6+PiQ7PCvz8+nxvNrNxeo6g/MfnldTug479WNBX1N/sr+mwgBICnRgAAAAFrn1pmvtPkU4EtvvR8nXDMtJ4ib8vxbBa46oq6uPr5yy5NZr/v//s8zBX9dPmD/TYQAkJRoQAAAAK2zuaomPjUy+xTgFS04Bbhhy4744o2zc8K/O2e33x15f1fxWs7rL1+/td1ef39m/02EAJCUaEAAAACtd1sDpwCXvd34KcDqmtoY+OuncsK3/5j4bLv+Dl/Vzl3x6WtnZNUw7OHn2+3192f230QIAEmJBgQAANB6m7c3cArwDw2fAqyvr48fTlicE/6d95v5UV1T286VR9w07eWc3x98b9vOdq9jf2P/TYQAkJRoQAAAAG2z9ynAnoMbPgX4q8dfzZn3xRtnx8atO1KoOuLtzdXRa+iUrHruemJ5KrXsT+y/iRAAkhINCAAAoG0aOgV4+R8WZc0pf+6tnPDvhGumxctvv59S1R/4j4nPZtX02etnxc5ddanWVOrsv4kQAJISDQgAAKDtbp+Vewpwd7j33NpN0efnU7Me+8SQ8pj98rqUq45Y+sbmnLof+os9YSHZfxMhACQlGhAAAEDbNXYK8K3N2+Oz18/KCdnunbsy7ZITg+5ZkFXbWXfMbdcbkuxv7L+JEACSEg0IAABg3/xyVu5v/H1lzJM5fxv84HMdKmCb8cLbOTVWrHwn7bJKlv03EQJAUqIBAQAA7JvN22vipL1OAe49zv/tgg73G3u1dfVx6s1PZNV58f8uTLuskmX/TYQAkJRoQAAAAPuuoVOAu8dpNz8Rm6p2pl1ig8Y+tSqr1o8PKY/VG7elXVZJsv8mQgBISjQgAACAffd+dcOnAE8aOT1WbNiadnmN2rZjV85vGI54ZGnaZZUk+28iBICkRAMCAADIjzsezz4FeOzQKTHv1Y1pl9Ws0VNeyqr7k9dMi81VNWmXVXLsv4kQAJISDQgAACA/tu3YFQN//VT0HFwevYdPjT8ufD3tklrkzU3b49ihU7JCwLvnrEi7rJJj/02EAJCUaEAAAAD5s31nbfxlzXux9r2qtEtplSvv/0tWAPiF0Y9HTW3HumlJsbP/JkIASEo0IAAAAJ59fVPO7xc+uuTNtMsqKfbfRAgASYkGBAAAQETEeb+ZnxUAfuPOeVFfX592WSXD/psIASAp0YAAAACIiJjy/Fs5pwAXrn437bJKhv03EQJAUqIBAQAAEBGxq7YuvvSL2VkB4L//flHaZZUM+28iBICkRAMCAABgt3vnrswKAD8xpDxef7e4bmjSUdl/EyEAJCUaEAAAALttqa6JE0dMzwoBr33sxbTLKgn230QIAEmJBgQAAMCerpv8YlYAeOKI6bGluibtsoqe/TcRAkBSogEBAACwp9ffrYpPDMm+Gci9c1emXVbRs/8mQgBISjQgAAAA9vbvv1+UFQB+8cbZsau2Lu2yipr9NxECQFKiAQEAALC3Ra+9mxUA9hxcHlOefyvtsoqa/TcRAkBSogEBAACwt/r6+vjGXU9lBYDn/WZ+2mUVNftvIgSApEQDAgAAoCGPLnkz5xTg4jXvpV1W0bL/JkIASEo0IAAAABpSU1sXXxj9eFYAeOX9f0m7rKJl/02EAJCUaEAAAAA05p45K7ICwGOHTok3Nm1Pu6yiZP9NhACQlGhAAAAANGbz9pr45DXTskLA0VNeSrusomT/TYQAkJRoQAAAADRlxCNLswLAT42cHtt27Eq7rKJj/02EAJCUaEAAAAA0ZfXGbfHxIdk3Axn71Kq0yyo69t9ECABJiQYEAABAcy4ZtzArADz15ieitq4+7bKKiv03EQJAUqIBAQAA0JyKle9kBYA9B5fH9BfeTrusomL/TYQAkJRoQAAAADSnvr4+zv7V3KwAcNA9C9Iuq6jYfxMhACQlGhAAAAAt8fDitTmnAJ9fuzntsoqG/TcRAkBSogEBAADQEjt31cVnr5+VFQD+aMLitMsqGvbfRAgASYkGBAAAQEvd9cTyrACw19Ap8fbm6rTLKgr230QIAEmJBgQAAEBLbaraGX1+PjUrBLxp2stpl1UU7L+JEACSEg0IAACA1hj28PNZAeCnr50RVTt3pV1Wh2f/TYQAkJRoQAAAALTGig1bc24G8ruK19Iuq8Oz/yZCAEhKNCAAAABa66KxlVkB4FfGPBl1dfVpl9Wh2X8TIQAkJRoQAAAArfXU8o05pwAfefaNtMvq0Oy/iRAAkhINCAAAgNaqr6+Pf7n9zzkh4Ll3PRWTFq2N6pratEvscOy/iRAAkhINCAAAgLb448LXcwLAPW8McsOUl+K1d7alXWaHYf9NhACQlGhAAAAAtMWOXbVx5m25pwD3Ht+975mY9eK6qN3PfyPQ/psIASAp0YAAAABoqy3VNXHH46/GF0Y/3mwQ+MUbZ8ddTyyPDVt2pF12Kuy/iRAAkhINCAAAgH21q7Yupr/wdvzbfz/dbBB43LAp8YPxi+OZVe9Gff3+cyrQ/psIASAp0YAAAADIp1Ubt8WoyS/Gyf81o9kw8Mzb/hy/q3gttu7YlXbZBWf/TYQAkJRoQAAAABTC9p218cDC1+OcO+c1GwSecM20+Pmflsayt7ekXXbB2H8TIQAkJRoQAAAAhbbk9U1x9R+XRO/hU5sNAwfdvSAeXfJm7NxVl3bZeWX/TYQAkJRoQAAAALSXTVU74965K+O0m59oNgg8ZdTMGDN9WbyxaXvaZeeF/TcRAsCiVV1dHb/+9a/j9NNPjyOOOCI6deoU3bt3j7POOismTpzY4utMmzYtBg4cGD169IjOnTtHjx49YuDAgTFt2rQCVq8BAQAA0P7q6upj7qsb4vvjFsYnhjQdBH5iSHlc/L8LY84rG6KurnhvGmL/TYQAsCgtW7Ys+vTpk3yAGxoDBgyIbdu2NXqN+vr6uPTSS5u8xqWXXlqwOyNpQAAAAKTpzU3b45YZy+KUUbOaPRV46s1PxP/988p4b9vOtMtuNftvIgSARWfDhg1xzDHHJB/eQYMGRXl5eSxevDjKy8tj0KBByWPnnHNOo9cZNmxYMq9fv34xYcKEqKysjAkTJkS/fv2Sx4YPH16Q96EBAQAA0BHs3FUXk597M759z4Jmg8Dew6fGT/+4JJa8vintslvM/psIAWDRufLKK5MP7siRIxucM2LEiGTOQw89lPP48uXLo6ysLDKZTPTv3z+2b8/+XYOqqqro379/ZDKZKCsrixUrVuT9fWhAAAAAdDSvrNsS1zyyNE4cMb3ZMPDrv5oXc1/dkHbJzbL/JkIAWFRqa2vj0EMPjUwmEz179oza2tpG533sYx9LAr69XXHFFcmHv6KiosFrVFRUJHOuuuqqvL6PCA0IAACAjmvrjl3xh6dfi3+5/c9NhoBPLFufdqnNsv8mQgBYVF5++eXkQ3vJJZc0Offiiy9O5q5evTr5e319ffTo0SMymUz07du3yWvs/p3Bo48+Ou+/BagBAQAA0NHV19fHwtXvxg8nLI7jh03NCv/+8abZRXFzEPtvIgSARWX+/Pkt/m2+PX/jb9y4ccnfV65cmfz9sssua/Iae94kZNWqVXl5D7tpQAAAABSTjVt3xK+fXB5fvHF29BxcHvfMyf/PZRWC/TcRAsCismTJkhZ/LXfP3wocPHhw8vfy8vLk77fffnuT17jtttuSuVOmTMnLe9hNAwIAAKAY1dbVx+MvrYt3i+SOwPbfRAgAi8q2bduiU6dOkclk4uSTT25y7kknnZR8wC+44ILk73fffXfy90mTJjV5jUmTJiVz77nnnlbVunbt2iZHZWWlBgQAAAAFJgAkQgBYdAYMGJB8cMePH9/gnPHjxydzMplMfP3rX08eu/nmm5O/T5s2rcnXmjp1ajL3lltuaVWde75+c0MDAgAAgMIQABIhACw6zzzzTJSVlUUmk4lOnTrFqFGjYs2aNVFTUxNr1qyJUaNGRadOnaJz587JB/yMM85Inn/dddclf589e3aTrzV79uxk7qhRo1pVpwAQAAAA0icAJEIAWJTGjRuXFfDtPQ466KC48847k//9zW9+M3lue50A9BVgAAAASJ8AkAgBYNFasmRJDBo0KA455JDkg3zggQfGGWecEU8//XQsXbo0+ftFF12UPK+9c2vAgAAAE3hJREFUfgOwORoQAAAAFJ79NxECwKJXW1sba9eujeXLl0dVVVXy9/vvvz/5gI8ZMyb5++TJk90FGAAAAPYT9t9ECABL1uWXX558wOfOnZv8feXKlcnfL7vssiavcemllyZzV61aldf6NCAAAAAoPPtvIgSAJWnnzp1x5JFHRiaTiR49ekRtbW3yWH19fXTv3j0ymUz07du3yev07ds3uUZ9fX1ea9SAAAAAoPDsv4kQAJakPW/00dDde/c8HVhRUdHgNSoqKpI5V1xxRd5r1IAAAACg8Oy/iRAAFqU1a9Y0+thjjz0WnTp1ikwmE8cff3xUV1fnzHnllVeirKwsMplM9O/fP7Zv3571+Pbt26N///6RyWSirKwsXn311by/Bw0IAAAACs/+mwgBYFE65JBD4swzz4x77703FixYEIsWLYoHH3wwzj///ORD3a1bt1i8eHGj1xgyZEgyt1+/fjFx4sRYuHBhTJw4Mfr165c8NnTo0IK8Bw0IAAAACs/+mwgBYFHq2rVr8uFtaJxwwglNhn8REXV1dfG9732vyetcfPHFUVdXV5D3oAEBAABA4dl/EyEALEoTJkyIiy66KE488cQ47LDDonPnztGjR4/42te+Fvfdd1/U1NS0+FpTpkyJc889N7p37x6dO3eO7t27x7nnnhtTp04t4DvQgAAAAKA92H8TIQAkJRoQAAAAFJ79NxECQFKiAQEAAEDh2X8TIQAkJRoQAAAAFJ79NxECQFKiAQEAAEDh2X8TIQAkJRoQAAAAFJ79NxECQFKiAQEAAEDh2X8TIQAkJRoQAAAAFJ79NxECQFKiAQEAAEDh2X8TIQAkJRoQAAAAFJ79NxECQFKiAQEAAEDh2X8TIQAkJRoQAAAAFJ79NxECQFKiAQEAAEDh2X8TIQAkJRoQAAAAFJ79NxECQFKiAQEAAEDh2X8TIQAkJRoQAAAAFJ79NxECQFKyevXqpAFVVlbG2rVrDcMwDMMwDMMwDMPI86isrEz236tXr047DiAlAkBSsWcDMgzDMAzDMAzDMAyj8KOysjLtOICUCABJhQDQMAzDMAzDMAzDMNp3CAD3XwJAUlFdXR2VlZVRWVkZq1evTv1IdGuPTfvaspGvYV0ZhRrWllGIYV0ZhRjWlVGoYW0ZhRjFuK5Wr16d7L+rq6vTjgNIiQAQWmjtWj+cSv5ZVxSKtUUhWFcUgnVFoVhbFIJ1RbESAEILafQUgnVFoVhbFIJ1RSFYVxSKtUUhWFcUKwEgtJBGTyFYVxSKtUUhWFcUgnVFoVhbFIJ1RbESAEILafQUgnVFoVhbFIJ1RSFYVxSKtUUhWFcUKwEgtJBGTyFYVxSKtUUhWFcUgnVFoVhbFIJ1RbESAEILafQUgnVFoVhbFIJ1RSFYVxSKtUUhWFcUKwEgtJBGTyFYVxSKtUUhWFcUgnVFoVhbFIJ1RbESAEILafQUgnVFoVhbFIJ1RSFYVxSKtUUhWFcUKwEgAAAAAJQwASAAAAAAlDABIAAAAACUMAEgAAAAAJQwASAAAAAAlDABIAAAAACUMAEgAAAAAJQwASAAAAAAlDABIAAAAACUMAEgAAAAAJQwASAAAAAAlDABILTAmjVr4qc//Wn07ds3unTpEt26dYvPfvazMWbMmKiqqkq7PIpMJpNp0TjttNPSLpUOYv369TF58uS45pprYsCAAXH44Ycn6+TCCy9s9fWmTZsWAwcOjB49ekTnzp2jR48eMXDgwJg2bVr+i6fDyse6Gjt2bIt72tixYwv6fug4/vKXv8QNN9wQAwYMiKOPPjo6d+4cXbt2jeOPPz4uvPDCmDt3bquup2cRkZ91pWexp/fffz8mTJgQP/nJT+LUU0+NXr16xUc+8pHo1KlTHHnkkXHaaafFTTfdFO+8806LrqdX0dEJAKEZ5eXl8bd/+7eN/stBnz59YuXKlWmXSRERANJaTa2T1gSA9fX1cemllzZ5vUsvvTTq6+sL92boMPKxrmym2dupp57aovXwne98J3bu3NnktfQsdsvXutKz2NOsWbNatBaOOOKImD59eqPX0asoFgJAaMKSJUuiS5cukclk4uCDD44bbrghFixYELNnz47vf//7SUPv27dvbN26Ne1yKRK7183ll18eS5cubXSsWrUq7VLpIPb8F8hjjjkmzjzzzDYFgMOGDUue169fv5gwYUJUVlbGhAkTol+/fsljw4cPL9ybocPIx7raczM9Y8aMJnvapk2bCvuG6BB69eoVmUwmunfvHj/60Y/iwQcfjMrKyqioqIjbbrstevTokayZCy64oMlr6Vnslq91pWexp1mzZsUxxxwT3/3ud+OOO+6Ihx9+OCoqKmL+/PnxwAMPxKBBg+Kggw6KTCYTnTt3jueee67B6+hVFAsBIDThn/7pnyKTyURZWVksWLAg5/Gbb745aejXXnttChVSjHavmZEjR6ZdCkVixIgRMXny5Fi3bl1ERKxevbrVQc3y5cujrKwsMplM9O/fP7Zv3571eFVVVfTv3z/peStWrMj326CDyce62nMzvXr16sIVS9E4++yz44EHHoja2toGH9+4cWP07t07WTeNfW1Tz2JP+VpXehZ7amw97elPf/pTsmbOO++8nMf1KoqJABAaUVlZmTT7yy67rME5dXV18clPfjIymUx069Ytampq2rlKipEAkH3VlqDmiiuuSJ5TUVHR4JyKiopkzlVXXZXHiikGAkDay+TJk5N188Mf/rDBOXoWrdWSdaVn0RZ9+/ZNvgq8N72KYiIAhEbseZT76aefbnTejTfemMybOXNmO1ZIsRIAsq9aG9TU19cnX4/q27dvk3P79OkTmUwmjj76aL9Vs58RANJetm7dmqybs88+O+dxPYu2aG5dRehZtM0pp5yS/CTUnvQqio0AEBrx5S9/OTKZTHTt2jV27drV6LwFCxYk/yIxYsSIdqyQYiUAZF+1NqhZuXJlsyead9vzR6z9DuX+RQBIe3n33XeTdXPOOefkPK5n0RbNrasIPYvWe+mll5LfAezfv3/WY3oVxUYACI044ogjIpPJxKc//ekm57333ntJMx80aFA7VUcx271eTjjhhOjdu3d8+MMfjoMPPjiOO+64+O53vxtPPPFE2iXSwbU2qCkvL0/m33777U3Ove2225K5U6ZMyVPFFIN9DQBPO+20OOqoo6JTp05x+OGHx+c///kYPnx4vPHGG4UtnKLz8MMPJ+vmZz/7Wc7jehZt0dy6itCzaJmqqqp49dVX49Zbb42PfvSjyZr5/e9/nzVPr6LYCAChAdXV1c1+hWBPXbt2jUwmE1/4whfaoTqK3e611dT45je/GZs3b067VDqo1gY1d999dzJ/0qRJTc6dNGlSMveee+7JU8UUg30NABsbH/7wh60lEnV1dfG5z30uWR8LFy7MmaNn0VotWVcRehaNa25tXH311Tlf3dWrKDYCQGjAhg0bkgZ9/vnnNzv/qKOOikwmE5/61KfaoTqKXZcuXeJf//Vf495774158+bFs88+GzNnzozhw4fH4YcfnvVfpt1Yhoa0NqjZ847l06ZNa3Lu1KlTk7m33HJLniqmGLQ1ADz22GPj6quvjoceeigqKyujsrIyJk6cGIMGDYoDDjggueZvf/vbwr4BisItt9ySrImBAwc2OEfPorVasq4i9Cwa11gA+JnPfKbR34PXqyg2AkBowOuvv5406O985zvNzj/mmGMik8lEr1692qE6it2mTZsafWzdunXRr1+/ZP3dcccd7VgZxaK1Qc11112XzJ89e3aTc2fPnp3MHTVqVJ4qphi0JQDcvHlzkz9mPnny5OjUqVNkMpno0qVLvP3223mqlmI0Z86cKCsri0wmE0cddVSsW7euwXl6Fq3R0nUVoWfRuE2bNsXSpUtj6dKlUVlZGRMmTIiBAwcme7zJkyfnPEevotgIAKEBTgCSppUrV0bnzp0jk8nEcccdl3Y5dEBOAFIIbQkAW+L6669Prnv99dfn7boUlxdeeCG6desWmUwmPvShD8WcOXManatn0VKtWVctpWexp9/97ndxwAEHxIEHHhhjx47NekyvotgIAKEBfgOQtJ199tnJGnzzzTfTLocOxm8AUgiFCgDXr1+ffK3un//5n/N2XYrHqlWronv37pHJZOKggw6Khx9+uMn5ehYt0dp11VJ6Fnv79re/HZlMJrp27Rrvvfde8ne9imIjAIRGuAswafrZz36WrKvKysq0y6GDaW1QM3ny5GS+u9TRmEIFgBERRx55ZGQyH9z9nP3Lm2++Gccee2xkMpk44IADYty4cc0+R8+iOW1ZV62hZ7Gn+++/P+kz999/f/J3vYpiIwCERnz5y19O/kvPrl27Gp23YMGCpJmPGDGiHSuklF199dUCQBrV2qBm5cqVyfzLLrusybmXXnppMnfVqlV5qphiUMgAcPd/VLOZ3r9s3LgxTjjhhGRd3XXXXS16np5FU9q6rlpDz2JPM2fOTNbb6NGjk7/rVRQbASA0YujQoUmTbuzOTxERN954YzJvxowZ7Vghpeyss85K1tUbb7yRdjl0MK0Naurr65OvSfXt27fJuX379o1MJhM9evRo8ofSKT3t8RXgr371q3m7Lh3b5s2b4+///u+TNfWLX/yixc/Vs2jMvqyrltKz2Nuedwj+1a9+lfxdr6LYCAChEc8880yz/0Wnrq4uPvnJT0Ymk4lDDz00ampq2rlKStHKlSuTO9Ade+yxaZdDB9SWoObyyy9PnlNRUdHgnIqKimTOFVdckceKKQaFCgBHjRqVXNedD/cPVVVV8aUvfSn55z58+PBWX0PPYm/5WFctoWextz3/w/yTTz6Z9ZheRTERAEITdn8NuKysLBYsWJDz+J53fho5cmT7F0jReeyxx5r8Svm6deuiX79+ybq69dZb27E6ikVbgppXXnklysrKIpPJRP/+/WP79u1Zj2/fvj369++f9LxXX321AJXTkbV2Xa1evToWL17c5JzJkycndzX/8Ic/7ETzfmDnzp1x5plnJmvpRz/6UZuuo2exp3ysKz2LvY0dOzaqq6ubnLPnb/d9/OMfz/n3eL2KYiIAhCYsXrw4/uZv/iYymUwcfPDBMXr06KioqIgnnngi63ccevfuHVu2bEm7XIpAz549o3v37vGDH/wgxo8fHwsWLIhnn302Zs2aFcOHD4/DDz88WVf/+I//GDt27Ei7ZDqAefPmxdixY5MxZsyYZJ186Utfynps7NixjV5nyJAhyfP69esXEydOjIULF8bEiROzguehQ4e235sjNfu6rp588snIZDLxD//wDzF69OiYOnVqLFq0KBYuXBgPPPBADBo0KPkaXaF+p4uO57zzzkv+mZ9++unx/PPPx9KlSxsdr7zySqPX0rPYLR/rSs9ibz179ozDDjssvv/978e4cePiqaeeiiVLlsS8efPiN7/5TdaJ086dO8esWbMavI5eRbEQAEIzHnvssfjIRz6SNO69R+/evWP58uVpl0mR6NmzZ6Nrac/xrW99KzZt2pR2uXQQF154YYvWze7RmLq6uvje977X5HMvvvjiqKura8d3R1r2dV3t3kw3N7p06RK//e1vU3iHpKE1ayqTyUTPnj0bvZaexW75WFd6Fntr6b+XH3300TFz5sxGr6NXUSwEgNACr732Wvz4xz+O3r17R5cuXeLQQw+N/v37x0033RRVVVVpl0cRmTNnTlx77bUxYMCA6N27dxx22GFRVlYWhx56aJx00klx2WWXNfh1c/Zv+QoAd5syZUqce+650b179+jcuXN07949zj333Jg6dWo7vBs6in1dV1u2bIk//OEPceWVV8bnP//5+NjHPhZdunSJzp07x0c/+tE4/fTT44Ybboj169en8O5ISz4DwN30LPKxrvQs9rZixYq455574vzzz4+TTz45PvrRj0ZZWVkcfPDB0atXr/jWt74VY8eObfF+T6+ioxMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJEwACAAAAQAkTAAIAAABACRMAAgAAAEAJ+/8Aje8/eSCGfX0AAAAASUVORK5CYII=\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5e113b3070>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(S[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9a0eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/tmp/ipykernel_16659/4048580583.py:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if information_set is \"S\":\n",
      "/tmp/ipykernel_16659/4048580583.py:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif information_set is \"log_S\":\n",
      "/tmp/ipykernel_16659/4048580583.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif information_set is \"normalized_log_S\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish preparing data!\n"
     ]
    }
   ],
   "source": [
    "#@title <font color='Blue'>**Prepare data to be fed into the deep hedging algorithm.**</font>\n",
    "\n",
    "payoff_T = payoff_func(S[:,-1]) # Payoff of the call option\n",
    "\n",
    "trade_set =  np.stack((S),axis=1) # Trading set\n",
    "\n",
    "if information_set is \"S\":\n",
    "  I =  np.stack((S),axis=1) # Information set\n",
    "elif information_set is \"log_S\":\n",
    "  I =  np.stack((np.log(S)),axis=1)\n",
    "elif information_set is \"normalized_log_S\":\n",
    "  I =  np.stack((np.log(S/S0)),axis=1)\n",
    "\n",
    "# Structure of xtrain:\n",
    "#   1) Trade set: [S]\n",
    "#   2) Information set: [S] \n",
    "#   3) payoff (dim = 1)\n",
    "x_all = []\n",
    "for i in range(N+1):\n",
    "  x_all += [trade_set[i,:,None]]\n",
    "  if i != N:\n",
    "    x_all += [I[i,:,None]]\n",
    "x_all += [payoff_T[:,None]]\n",
    "\n",
    "# Split the entire sample into a training sample and a testing sample.\n",
    "test_size = int(Ktrain*Ktest_ratio)\n",
    "[xtrain, xtest] = train_test_split(x_all, test_size=test_size)\n",
    "[S_train, S_test] = train_test_split([S], test_size=test_size)\n",
    "[option_payoff_train, option_payoff_test] = \\\n",
    "    train_test_split([x_all[-1]], test_size=test_size)\n",
    "\n",
    "print(\"Finish preparing data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d391aa39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 17:47:10.337720: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-16 17:47:10.337826: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-16 17:47:10.338970: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1) (None, 1)\n",
      "(None, 2, 2) None\n",
      "(None, 4) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 3, 2) None\n",
      "(None, 6) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 4, 2) None\n",
      "(None, 8) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 5, 2) None\n",
      "(None, 10) None\n",
      "(None, 1) strategyhelper\n",
      "(None, 1) (None, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <tensorflow.python.keras.engine.functional.Functional object at 0x7f5e10433cd0>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title <font color='Blue'>**Run the Deep Hedging Algorithm (Recurrent Network)!**</font>\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "# Setup and compile the model\n",
    "model_recurrent = Deep_Hedging_Model_Transformer(N=N, d=d, m=m, risk_free=risk_free, \\\n",
    "          dt = dt, strategy_type=\"recurrent\", epsilon = epsilon,maxT=maxT, \\\n",
    "          use_batch_norm = use_batch_norm, kernel_initializer = kernel_initializer, \\\n",
    "          activation_dense = activation_dense, activation_output = activation_output, \\\n",
    "          final_period_cost = final_period_cost)\n",
    "\n",
    "loss = Entropy(model_recurrent.output,None,loss_param)\n",
    "model_recurrent.add_loss(loss)\n",
    "\n",
    "model_recurrent.compile(optimizer=optimizer)\n",
    "\n",
    "model_recurrent.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1d8fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "prc_0 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "information_set_0 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           prc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2)            0           information_set_0[0][0]          \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack (TFOpLambda)           (None, 2, 2)         0           concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2, 2)         4           tf.stack[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 2, 2)         5634        layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2, 2)         0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 2, 2)         0           dropout[0][0]                    \n",
      "                                                                 tf.stack[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2, 2)         4           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 2, 2)         6           layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 2)         0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2, 2)         6           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4)            0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            5           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "information_set_1 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           information_set_1[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_1 (TFOpLambda)         (None, 3, 2)         0           concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 3, 2)         4           tf.stack_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 3, 2)         8450        layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 3, 2)         0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 3, 2)         0           dropout_2[0][0]                  \n",
      "                                                                 tf.stack_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 3, 2)         4           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 3, 3)         9           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 3, 3)         0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 3, 2)         8           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6)            0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            7           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "information_set_2 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2)            0           information_set_2[0][0]          \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_2 (TFOpLambda)         (None, 4, 2)         0           concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 4, 2)         4           tf.stack_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 4, 2)         11266       layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4, 2)         0           multi_head_attention_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 4, 2)         0           dropout_4[0][0]                  \n",
      "                                                                 tf.stack_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 4, 2)         4           tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 4, 4)         12          layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 4)         0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 4, 2)         10          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 8)            0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            9           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "information_set_3 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2)            0           information_set_3[0][0]          \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_3 (TFOpLambda)         (None, 5, 2)         0           concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 5, 2)         4           tf.stack_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 5, 2)         14082       layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 5, 2)         0           multi_head_attention_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 5, 2)         0           dropout_6[0][0]                  \n",
      "                                                                 tf.stack_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 5, 2)         4           tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 5, 5)         15          layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 5, 5)         0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 5, 2)         12          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10)           0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            11          reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "information_set_4 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2)            0           information_set_4[0][0]          \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_4 (TFOpLambda)         (None, 5, 2)         0           concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 5, 2)         4           tf.stack_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 5, 2)         14082       layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 5, 2)         0           multi_head_attention_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 5, 2)         0           dropout_8[0][0]                  \n",
      "                                                                 tf.stack_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 5, 2)         4           tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 5, 5)         15          layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 5, 5)         0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 5, 2)         12          dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10)           0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            11          reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "information_set_5 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2)            0           information_set_5[0][0]          \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_5 (TFOpLambda)         (None, 5, 2)         0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, 5, 2)         4           tf.stack_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 5, 2)         14082       layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 5, 2)         0           multi_head_attention_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 5, 2)         0           dropout_10[0][0]                 \n",
      "                                                                 tf.stack_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, 5, 2)         4           tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 5, 5)         15          layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 5, 5)         0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 5, 2)         12          dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10)           0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            11          reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "information_set_6 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 2)            0           information_set_6[0][0]          \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_6 (TFOpLambda)         (None, 5, 2)         0           concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 5, 2)         4           tf.stack_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, 5, 2)         14082       layer_normalization_12[0][0]     \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 5, 2)         0           multi_head_attention_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 5, 2)         0           dropout_12[0][0]                 \n",
      "                                                                 tf.stack_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 5, 2)         4           tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 5, 5)         15          layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 5, 5)         0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 5, 2)         12          dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10)           0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            11          reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "information_set_7 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2)            0           information_set_7[0][0]          \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_7 (TFOpLambda)         (None, 5, 2)         0           concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 5, 2)         4           tf.stack_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, 5, 2)         14082       layer_normalization_14[0][0]     \n",
      "                                                                 layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 5, 2)         0           multi_head_attention_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 5, 2)         0           dropout_14[0][0]                 \n",
      "                                                                 tf.stack_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, 5, 2)         4           tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 5, 5)         15          layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 5, 5)         0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 5, 2)         12          dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10)           0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            11          reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "information_set_8 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 2)            0           information_set_8[0][0]          \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_8 (TFOpLambda)         (None, 5, 2)         0           concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 5, 2)         4           tf.stack_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe (None, 5, 2)         14082       layer_normalization_16[0][0]     \n",
      "                                                                 layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 5, 2)         0           multi_head_attention_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 5, 2)         0           dropout_16[0][0]                 \n",
      "                                                                 tf.stack_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, 5, 2)         4           tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 5, 5)         15          layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 5, 5)         0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 5, 2)         12          dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10)           0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            11          reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "information_set_9 (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 2)            0           information_set_9[0][0]          \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_9 (TFOpLambda)         (None, 5, 2)         0           concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_18 (LayerNo (None, 5, 2)         4           tf.stack_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_9 (MultiHe (None, 5, 2)         14082       layer_normalization_18[0][0]     \n",
      "                                                                 layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 5, 2)         0           multi_head_attention_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 5, 2)         0           dropout_18[0][0]                 \n",
      "                                                                 tf.stack_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 5, 2)         4           tf.__operators__.add_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 5, 5)         15          layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 5, 5)         0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 5, 2)         12          dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 10)           0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            11          reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "information_set_10 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 2)            0           information_set_10[0][0]         \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_10 (TFOpLambda)        (None, 5, 2)         0           concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_20 (LayerNo (None, 5, 2)         4           tf.stack_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_10 (MultiH (None, 5, 2)         14082       layer_normalization_20[0][0]     \n",
      "                                                                 layer_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 5, 2)         0           multi_head_attention_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_10 (TFOpLa (None, 5, 2)         0           dropout_20[0][0]                 \n",
      "                                                                 tf.stack_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_21 (LayerNo (None, 5, 2)         4           tf.__operators__.add_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 5, 5)         15          layer_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 5, 5)         0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 5, 2)         12          dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 10)           0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            11          reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_11 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2)            0           information_set_11[0][0]         \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_11 (TFOpLambda)        (None, 5, 2)         0           concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_22 (LayerNo (None, 5, 2)         4           tf.stack_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_11 (MultiH (None, 5, 2)         14082       layer_normalization_22[0][0]     \n",
      "                                                                 layer_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 5, 2)         0           multi_head_attention_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_11 (TFOpLa (None, 5, 2)         0           dropout_22[0][0]                 \n",
      "                                                                 tf.stack_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_23 (LayerNo (None, 5, 2)         4           tf.__operators__.add_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 5, 5)         15          layer_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 5, 5)         0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 5, 2)         12          dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 10)           0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            11          reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_12 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 2)            0           information_set_12[0][0]         \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_12 (TFOpLambda)        (None, 5, 2)         0           concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_24 (LayerNo (None, 5, 2)         4           tf.stack_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_12 (MultiH (None, 5, 2)         14082       layer_normalization_24[0][0]     \n",
      "                                                                 layer_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 5, 2)         0           multi_head_attention_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (None, 5, 2)         0           dropout_24[0][0]                 \n",
      "                                                                 tf.stack_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_25 (LayerNo (None, 5, 2)         4           tf.__operators__.add_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 5, 5)         15          layer_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 5, 5)         0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 5, 2)         12          dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 10)           0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            11          reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_13 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 2)            0           information_set_13[0][0]         \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_13 (TFOpLambda)        (None, 5, 2)         0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_26 (LayerNo (None, 5, 2)         4           tf.stack_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_13 (MultiH (None, 5, 2)         14082       layer_normalization_26[0][0]     \n",
      "                                                                 layer_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 5, 2)         0           multi_head_attention_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_13 (TFOpLa (None, 5, 2)         0           dropout_26[0][0]                 \n",
      "                                                                 tf.stack_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_27 (LayerNo (None, 5, 2)         4           tf.__operators__.add_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 5, 5)         15          layer_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 5, 5)         0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 5, 2)         12          dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 10)           0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            11          reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_14 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 2)            0           information_set_14[0][0]         \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_14 (TFOpLambda)        (None, 5, 2)         0           concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_28 (LayerNo (None, 5, 2)         4           tf.stack_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_14 (MultiH (None, 5, 2)         14082       layer_normalization_28[0][0]     \n",
      "                                                                 layer_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 5, 2)         0           multi_head_attention_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_14 (TFOpLa (None, 5, 2)         0           dropout_28[0][0]                 \n",
      "                                                                 tf.stack_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_29 (LayerNo (None, 5, 2)         4           tf.__operators__.add_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 5, 5)         15          layer_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 5, 5)         0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 5, 2)         12          dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 10)           0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            11          reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_15 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 2)            0           information_set_15[0][0]         \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_15 (TFOpLambda)        (None, 5, 2)         0           concatenate_11[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "                                                                 concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_30 (LayerNo (None, 5, 2)         4           tf.stack_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_15 (MultiH (None, 5, 2)         14082       layer_normalization_30[0][0]     \n",
      "                                                                 layer_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 5, 2)         0           multi_head_attention_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_15 (TFOpLa (None, 5, 2)         0           dropout_30[0][0]                 \n",
      "                                                                 tf.stack_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_31 (LayerNo (None, 5, 2)         4           tf.__operators__.add_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 5, 5)         15          layer_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 5, 5)         0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 5, 2)         12          dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 10)           0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            11          reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_16 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 2)            0           information_set_16[0][0]         \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_16 (TFOpLambda)        (None, 5, 2)         0           concatenate_12[0][0]             \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "                                                                 concatenate_15[0][0]             \n",
      "                                                                 concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_32 (LayerNo (None, 5, 2)         4           tf.stack_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_16 (MultiH (None, 5, 2)         14082       layer_normalization_32[0][0]     \n",
      "                                                                 layer_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 5, 2)         0           multi_head_attention_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_16 (TFOpLa (None, 5, 2)         0           dropout_32[0][0]                 \n",
      "                                                                 tf.stack_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_33 (LayerNo (None, 5, 2)         4           tf.__operators__.add_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 5, 5)         15          layer_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 5, 5)         0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 5, 2)         12          dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 10)           0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            11          reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_17 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 2)            0           information_set_17[0][0]         \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_17 (TFOpLambda)        (None, 5, 2)         0           concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "                                                                 concatenate_15[0][0]             \n",
      "                                                                 concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_34 (LayerNo (None, 5, 2)         4           tf.stack_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_17 (MultiH (None, 5, 2)         14082       layer_normalization_34[0][0]     \n",
      "                                                                 layer_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 5, 2)         0           multi_head_attention_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_17 (TFOpLa (None, 5, 2)         0           dropout_34[0][0]                 \n",
      "                                                                 tf.stack_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_35 (LayerNo (None, 5, 2)         4           tf.__operators__.add_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5, 5)         15          layer_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 5, 5)         0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 5, 2)         12          dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 10)           0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            11          reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_18 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 2)            0           information_set_18[0][0]         \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_18 (TFOpLambda)        (None, 5, 2)         0           concatenate_14[0][0]             \n",
      "                                                                 concatenate_15[0][0]             \n",
      "                                                                 concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "                                                                 concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_36 (LayerNo (None, 5, 2)         4           tf.stack_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_18 (MultiH (None, 5, 2)         14082       layer_normalization_36[0][0]     \n",
      "                                                                 layer_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 5, 2)         0           multi_head_attention_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_18 (TFOpLa (None, 5, 2)         0           dropout_36[0][0]                 \n",
      "                                                                 tf.stack_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_37 (LayerNo (None, 5, 2)         4           tf.__operators__.add_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 5, 5)         15          layer_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 5, 5)         0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5, 2)         12          dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 10)           0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            11          reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_19 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 2)            0           information_set_19[0][0]         \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_19 (TFOpLambda)        (None, 5, 2)         0           concatenate_15[0][0]             \n",
      "                                                                 concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "                                                                 concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_38 (LayerNo (None, 5, 2)         4           tf.stack_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_19 (MultiH (None, 5, 2)         14082       layer_normalization_38[0][0]     \n",
      "                                                                 layer_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 5, 2)         0           multi_head_attention_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_19 (TFOpLa (None, 5, 2)         0           dropout_38[0][0]                 \n",
      "                                                                 tf.stack_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_39 (LayerNo (None, 5, 2)         4           tf.__operators__.add_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 5, 5)         15          layer_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 5, 5)         0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 5, 2)         12          dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 10)           0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            11          reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_20 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 2)            0           information_set_20[0][0]         \n",
      "                                                                 dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_20 (TFOpLambda)        (None, 5, 2)         0           concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "                                                                 concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "                                                                 concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_40 (LayerNo (None, 5, 2)         4           tf.stack_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_20 (MultiH (None, 5, 2)         14082       layer_normalization_40[0][0]     \n",
      "                                                                 layer_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 5, 2)         0           multi_head_attention_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_20 (TFOpLa (None, 5, 2)         0           dropout_40[0][0]                 \n",
      "                                                                 tf.stack_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_41 (LayerNo (None, 5, 2)         4           tf.__operators__.add_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 5, 5)         15          layer_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 5, 5)         0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5, 2)         12          dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 10)           0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            11          reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_21 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 2)            0           information_set_21[0][0]         \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_21 (TFOpLambda)        (None, 5, 2)         0           concatenate_17[0][0]             \n",
      "                                                                 concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "                                                                 concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_42 (LayerNo (None, 5, 2)         4           tf.stack_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_21 (MultiH (None, 5, 2)         14082       layer_normalization_42[0][0]     \n",
      "                                                                 layer_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 5, 2)         0           multi_head_attention_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_21 (TFOpLa (None, 5, 2)         0           dropout_42[0][0]                 \n",
      "                                                                 tf.stack_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_43 (LayerNo (None, 5, 2)         4           tf.__operators__.add_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 5, 5)         15          layer_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 5, 5)         0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 5, 2)         12          dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 10)           0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            11          reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_22 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 2)            0           information_set_22[0][0]         \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_22 (TFOpLambda)        (None, 5, 2)         0           concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "                                                                 concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_44 (LayerNo (None, 5, 2)         4           tf.stack_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_22 (MultiH (None, 5, 2)         14082       layer_normalization_44[0][0]     \n",
      "                                                                 layer_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 5, 2)         0           multi_head_attention_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_22 (TFOpLa (None, 5, 2)         0           dropout_44[0][0]                 \n",
      "                                                                 tf.stack_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_45 (LayerNo (None, 5, 2)         4           tf.__operators__.add_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 5, 5)         15          layer_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 5, 5)         0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 5, 2)         12          dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_0 (Lambda)      (None, 1)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 10)           0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           absolutechanges_0[0][0]          \n",
      "                                                                 prc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1)            11          reshape_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_23 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cost_0 (Lambda)                 (None, 1)            0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_1 (Subtract)      (None, 1)            0           dense_1[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 2)            0           information_set_23[0][0]         \n",
      "                                                                 dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "costDot_0 (Lambda)              (None, 1)            0           cost_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           dense[0][0]                      \n",
      "                                                                 prc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_1 (Lambda)      (None, 1)            0           diff_strategy_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prc_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_23 (TFOpLambda)        (None, 5, 2)         0           concatenate_19[0][0]             \n",
      "                                                                 concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "                                                                 concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "wealth_0 (Subtract)             (None, 1)            0           costDot_0[0][0]                  \n",
      "                                                                 dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1)            0           absolutechanges_1[0][0]          \n",
      "                                                                 prc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_46 (LayerNo (None, 5, 2)         4           tf.stack_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           wealth_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_1 (Lambda)                 (None, 1)            0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_2 (Subtract)      (None, 1)            0           dense_2[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_23 (MultiH (None, 5, 2)         14082       layer_normalization_46[0][0]     \n",
      "                                                                 layer_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "costDot_1 (Subtract)            (None, 1)            0           lambda_1[0][0]                   \n",
      "                                                                 cost_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 1)            0           diff_strategy_1[0][0]            \n",
      "                                                                 prc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_2 (Lambda)      (None, 1)            0           diff_strategy_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prc_2 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 5, 2)         0           multi_head_attention_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "wealth_1 (Subtract)             (None, 1)            0           costDot_1[0][0]                  \n",
      "                                                                 dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 1)            0           absolutechanges_2[0][0]          \n",
      "                                                                 prc_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_23 (TFOpLa (None, 5, 2)         0           dropout_46[0][0]                 \n",
      "                                                                 tf.stack_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           wealth_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_2 (Lambda)                 (None, 1)            0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_3 (Subtract)      (None, 1)            0           dense_3[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_47 (LayerNo (None, 5, 2)         4           tf.__operators__.add_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "costDot_2 (Subtract)            (None, 1)            0           lambda_2[0][0]                   \n",
      "                                                                 cost_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 1)            0           diff_strategy_2[0][0]            \n",
      "                                                                 prc_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_3 (Lambda)      (None, 1)            0           diff_strategy_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prc_3 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5, 5)         15          layer_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "wealth_2 (Subtract)             (None, 1)            0           costDot_2[0][0]                  \n",
      "                                                                 dot_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_6 (Dot)                     (None, 1)            0           absolutechanges_3[0][0]          \n",
      "                                                                 prc_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 5, 5)         0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           wealth_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_3 (Lambda)                 (None, 1)            0           dot_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_4 (Subtract)      (None, 1)            0           dense_4[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 5, 2)         12          dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "costDot_3 (Subtract)            (None, 1)            0           lambda_3[0][0]                   \n",
      "                                                                 cost_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_7 (Dot)                     (None, 1)            0           diff_strategy_3[0][0]            \n",
      "                                                                 prc_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_4 (Lambda)      (None, 1)            0           diff_strategy_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prc_4 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 10)           0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "wealth_3 (Subtract)             (None, 1)            0           costDot_3[0][0]                  \n",
      "                                                                 dot_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 1)            0           absolutechanges_4[0][0]          \n",
      "                                                                 prc_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            11          reshape_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_24 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           wealth_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_4 (Lambda)                 (None, 1)            0           dot_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_5 (Subtract)      (None, 1)            0           dense_5[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 2)            0           information_set_24[0][0]         \n",
      "                                                                 dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "costDot_4 (Subtract)            (None, 1)            0           lambda_4[0][0]                   \n",
      "                                                                 cost_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_9 (Dot)                     (None, 1)            0           diff_strategy_4[0][0]            \n",
      "                                                                 prc_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_5 (Lambda)      (None, 1)            0           diff_strategy_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prc_5 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_24 (TFOpLambda)        (None, 5, 2)         0           concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "                                                                 concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "wealth_4 (Subtract)             (None, 1)            0           costDot_4[0][0]                  \n",
      "                                                                 dot_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_10 (Dot)                    (None, 1)            0           absolutechanges_5[0][0]          \n",
      "                                                                 prc_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_48 (LayerNo (None, 5, 2)         4           tf.stack_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           wealth_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_5 (Lambda)                 (None, 1)            0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_6 (Subtract)      (None, 1)            0           dense_6[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_24 (MultiH (None, 5, 2)         14082       layer_normalization_48[0][0]     \n",
      "                                                                 layer_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "costDot_5 (Subtract)            (None, 1)            0           lambda_5[0][0]                   \n",
      "                                                                 cost_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_11 (Dot)                    (None, 1)            0           diff_strategy_5[0][0]            \n",
      "                                                                 prc_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_6 (Lambda)      (None, 1)            0           diff_strategy_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prc_6 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 5, 2)         0           multi_head_attention_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "wealth_5 (Subtract)             (None, 1)            0           costDot_5[0][0]                  \n",
      "                                                                 dot_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_12 (Dot)                    (None, 1)            0           absolutechanges_6[0][0]          \n",
      "                                                                 prc_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_24 (TFOpLa (None, 5, 2)         0           dropout_48[0][0]                 \n",
      "                                                                 tf.stack_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           wealth_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_6 (Lambda)                 (None, 1)            0           dot_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_7 (Subtract)      (None, 1)            0           dense_7[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_49 (LayerNo (None, 5, 2)         4           tf.__operators__.add_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "costDot_6 (Subtract)            (None, 1)            0           lambda_6[0][0]                   \n",
      "                                                                 cost_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_13 (Dot)                    (None, 1)            0           diff_strategy_6[0][0]            \n",
      "                                                                 prc_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_7 (Lambda)      (None, 1)            0           diff_strategy_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prc_7 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 5, 5)         15          layer_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "wealth_6 (Subtract)             (None, 1)            0           costDot_6[0][0]                  \n",
      "                                                                 dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_14 (Dot)                    (None, 1)            0           absolutechanges_7[0][0]          \n",
      "                                                                 prc_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 5, 5)         0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           wealth_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_7 (Lambda)                 (None, 1)            0           dot_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_8 (Subtract)      (None, 1)            0           dense_8[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 5, 2)         12          dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "costDot_7 (Subtract)            (None, 1)            0           lambda_7[0][0]                   \n",
      "                                                                 cost_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_15 (Dot)                    (None, 1)            0           diff_strategy_7[0][0]            \n",
      "                                                                 prc_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_8 (Lambda)      (None, 1)            0           diff_strategy_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prc_8 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 10)           0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "wealth_7 (Subtract)             (None, 1)            0           costDot_7[0][0]                  \n",
      "                                                                 dot_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_16 (Dot)                    (None, 1)            0           absolutechanges_8[0][0]          \n",
      "                                                                 prc_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            11          reshape_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_25 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1)            0           wealth_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_8 (Lambda)                 (None, 1)            0           dot_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_9 (Subtract)      (None, 1)            0           dense_9[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 2)            0           information_set_25[0][0]         \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "costDot_8 (Subtract)            (None, 1)            0           lambda_8[0][0]                   \n",
      "                                                                 cost_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_17 (Dot)                    (None, 1)            0           diff_strategy_8[0][0]            \n",
      "                                                                 prc_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_9 (Lambda)      (None, 1)            0           diff_strategy_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prc_9 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_25 (TFOpLambda)        (None, 5, 2)         0           concatenate_21[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "                                                                 concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "wealth_8 (Subtract)             (None, 1)            0           costDot_8[0][0]                  \n",
      "                                                                 dot_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_18 (Dot)                    (None, 1)            0           absolutechanges_9[0][0]          \n",
      "                                                                 prc_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_50 (LayerNo (None, 5, 2)         4           tf.stack_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           wealth_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_9 (Lambda)                 (None, 1)            0           dot_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_10 (Subtract)     (None, 1)            0           dense_10[0][0]                   \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_25 (MultiH (None, 5, 2)         14082       layer_normalization_50[0][0]     \n",
      "                                                                 layer_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "costDot_9 (Subtract)            (None, 1)            0           lambda_9[0][0]                   \n",
      "                                                                 cost_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_19 (Dot)                    (None, 1)            0           diff_strategy_9[0][0]            \n",
      "                                                                 prc_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_10 (Lambda)     (None, 1)            0           diff_strategy_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_10 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 5, 2)         0           multi_head_attention_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "wealth_9 (Subtract)             (None, 1)            0           costDot_9[0][0]                  \n",
      "                                                                 dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_20 (Dot)                    (None, 1)            0           absolutechanges_10[0][0]         \n",
      "                                                                 prc_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_25 (TFOpLa (None, 5, 2)         0           dropout_50[0][0]                 \n",
      "                                                                 tf.stack_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1)            0           wealth_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cost_10 (Lambda)                (None, 1)            0           dot_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_11 (Subtract)     (None, 1)            0           dense_11[0][0]                   \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_51 (LayerNo (None, 5, 2)         4           tf.__operators__.add_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "costDot_10 (Subtract)           (None, 1)            0           lambda_10[0][0]                  \n",
      "                                                                 cost_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_21 (Dot)                    (None, 1)            0           diff_strategy_10[0][0]           \n",
      "                                                                 prc_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_11 (Lambda)     (None, 1)            0           diff_strategy_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_11 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 5, 5)         15          layer_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "wealth_10 (Subtract)            (None, 1)            0           costDot_10[0][0]                 \n",
      "                                                                 dot_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_22 (Dot)                    (None, 1)            0           absolutechanges_11[0][0]         \n",
      "                                                                 prc_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 5, 5)         0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           wealth_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_11 (Lambda)                (None, 1)            0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_12 (Subtract)     (None, 1)            0           dense_12[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 5, 2)         12          dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "costDot_11 (Subtract)           (None, 1)            0           lambda_11[0][0]                  \n",
      "                                                                 cost_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_23 (Dot)                    (None, 1)            0           diff_strategy_11[0][0]           \n",
      "                                                                 prc_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_12 (Lambda)     (None, 1)            0           diff_strategy_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_12 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 10)           0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "wealth_11 (Subtract)            (None, 1)            0           costDot_11[0][0]                 \n",
      "                                                                 dot_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_24 (Dot)                    (None, 1)            0           absolutechanges_12[0][0]         \n",
      "                                                                 prc_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1)            11          reshape_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_26 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1)            0           wealth_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_12 (Lambda)                (None, 1)            0           dot_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_13 (Subtract)     (None, 1)            0           dense_13[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 2)            0           information_set_26[0][0]         \n",
      "                                                                 dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "costDot_12 (Subtract)           (None, 1)            0           lambda_12[0][0]                  \n",
      "                                                                 cost_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_25 (Dot)                    (None, 1)            0           diff_strategy_12[0][0]           \n",
      "                                                                 prc_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_13 (Lambda)     (None, 1)            0           diff_strategy_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_13 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_26 (TFOpLambda)        (None, 5, 2)         0           concatenate_22[0][0]             \n",
      "                                                                 concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "wealth_12 (Subtract)            (None, 1)            0           costDot_12[0][0]                 \n",
      "                                                                 dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_26 (Dot)                    (None, 1)            0           absolutechanges_13[0][0]         \n",
      "                                                                 prc_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_52 (LayerNo (None, 5, 2)         4           tf.stack_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1)            0           wealth_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_13 (Lambda)                (None, 1)            0           dot_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_14 (Subtract)     (None, 1)            0           dense_14[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_26 (MultiH (None, 5, 2)         14082       layer_normalization_52[0][0]     \n",
      "                                                                 layer_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "costDot_13 (Subtract)           (None, 1)            0           lambda_13[0][0]                  \n",
      "                                                                 cost_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_27 (Dot)                    (None, 1)            0           diff_strategy_13[0][0]           \n",
      "                                                                 prc_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_14 (Lambda)     (None, 1)            0           diff_strategy_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_14 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 5, 2)         0           multi_head_attention_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "wealth_13 (Subtract)            (None, 1)            0           costDot_13[0][0]                 \n",
      "                                                                 dot_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_28 (Dot)                    (None, 1)            0           absolutechanges_14[0][0]         \n",
      "                                                                 prc_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_26 (TFOpLa (None, 5, 2)         0           dropout_52[0][0]                 \n",
      "                                                                 tf.stack_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1)            0           wealth_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_14 (Lambda)                (None, 1)            0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_15 (Subtract)     (None, 1)            0           dense_15[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_53 (LayerNo (None, 5, 2)         4           tf.__operators__.add_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "costDot_14 (Subtract)           (None, 1)            0           lambda_14[0][0]                  \n",
      "                                                                 cost_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_29 (Dot)                    (None, 1)            0           diff_strategy_14[0][0]           \n",
      "                                                                 prc_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_15 (Lambda)     (None, 1)            0           diff_strategy_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_15 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5, 5)         15          layer_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "wealth_14 (Subtract)            (None, 1)            0           costDot_14[0][0]                 \n",
      "                                                                 dot_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_30 (Dot)                    (None, 1)            0           absolutechanges_15[0][0]         \n",
      "                                                                 prc_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 5, 5)         0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1)            0           wealth_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_15 (Lambda)                (None, 1)            0           dot_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_16 (Subtract)     (None, 1)            0           dense_16[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 5, 2)         12          dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "costDot_15 (Subtract)           (None, 1)            0           lambda_15[0][0]                  \n",
      "                                                                 cost_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_31 (Dot)                    (None, 1)            0           diff_strategy_15[0][0]           \n",
      "                                                                 prc_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_16 (Lambda)     (None, 1)            0           diff_strategy_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_16 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)            (None, 10)           0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "wealth_15 (Subtract)            (None, 1)            0           costDot_15[0][0]                 \n",
      "                                                                 dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_32 (Dot)                    (None, 1)            0           absolutechanges_16[0][0]         \n",
      "                                                                 prc_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1)            11          reshape_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_27 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1)            0           wealth_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_16 (Lambda)                (None, 1)            0           dot_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_17 (Subtract)     (None, 1)            0           dense_17[0][0]                   \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 2)            0           information_set_27[0][0]         \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "costDot_16 (Subtract)           (None, 1)            0           lambda_16[0][0]                  \n",
      "                                                                 cost_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_33 (Dot)                    (None, 1)            0           diff_strategy_16[0][0]           \n",
      "                                                                 prc_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_17 (Lambda)     (None, 1)            0           diff_strategy_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_17 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_27 (TFOpLambda)        (None, 5, 2)         0           concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "                                                                 concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "wealth_16 (Subtract)            (None, 1)            0           costDot_16[0][0]                 \n",
      "                                                                 dot_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_34 (Dot)                    (None, 1)            0           absolutechanges_17[0][0]         \n",
      "                                                                 prc_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_54 (LayerNo (None, 5, 2)         4           tf.stack_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1)            0           wealth_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_17 (Lambda)                (None, 1)            0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_18 (Subtract)     (None, 1)            0           dense_18[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_27 (MultiH (None, 5, 2)         14082       layer_normalization_54[0][0]     \n",
      "                                                                 layer_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "costDot_17 (Subtract)           (None, 1)            0           lambda_17[0][0]                  \n",
      "                                                                 cost_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_35 (Dot)                    (None, 1)            0           diff_strategy_17[0][0]           \n",
      "                                                                 prc_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_18 (Lambda)     (None, 1)            0           diff_strategy_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_18 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 5, 2)         0           multi_head_attention_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "wealth_17 (Subtract)            (None, 1)            0           costDot_17[0][0]                 \n",
      "                                                                 dot_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_36 (Dot)                    (None, 1)            0           absolutechanges_18[0][0]         \n",
      "                                                                 prc_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_27 (TFOpLa (None, 5, 2)         0           dropout_54[0][0]                 \n",
      "                                                                 tf.stack_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1)            0           wealth_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_18 (Lambda)                (None, 1)            0           dot_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_19 (Subtract)     (None, 1)            0           dense_19[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_55 (LayerNo (None, 5, 2)         4           tf.__operators__.add_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "costDot_18 (Subtract)           (None, 1)            0           lambda_18[0][0]                  \n",
      "                                                                 cost_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_37 (Dot)                    (None, 1)            0           diff_strategy_18[0][0]           \n",
      "                                                                 prc_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_19 (Lambda)     (None, 1)            0           diff_strategy_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_19 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 5, 5)         15          layer_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "wealth_18 (Subtract)            (None, 1)            0           costDot_18[0][0]                 \n",
      "                                                                 dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_38 (Dot)                    (None, 1)            0           absolutechanges_19[0][0]         \n",
      "                                                                 prc_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 5, 5)         0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1)            0           wealth_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_19 (Lambda)                (None, 1)            0           dot_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_20 (Subtract)     (None, 1)            0           dense_20[0][0]                   \n",
      "                                                                 dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 5, 2)         12          dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "costDot_19 (Subtract)           (None, 1)            0           lambda_19[0][0]                  \n",
      "                                                                 cost_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_39 (Dot)                    (None, 1)            0           diff_strategy_19[0][0]           \n",
      "                                                                 prc_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_20 (Lambda)     (None, 1)            0           diff_strategy_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_20 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)            (None, 10)           0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "wealth_19 (Subtract)            (None, 1)            0           costDot_19[0][0]                 \n",
      "                                                                 dot_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_40 (Dot)                    (None, 1)            0           absolutechanges_20[0][0]         \n",
      "                                                                 prc_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            11          reshape_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_28 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1)            0           wealth_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_20 (Lambda)                (None, 1)            0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_21 (Subtract)     (None, 1)            0           dense_21[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 2)            0           information_set_28[0][0]         \n",
      "                                                                 dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "costDot_20 (Subtract)           (None, 1)            0           lambda_20[0][0]                  \n",
      "                                                                 cost_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_41 (Dot)                    (None, 1)            0           diff_strategy_20[0][0]           \n",
      "                                                                 prc_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_21 (Lambda)     (None, 1)            0           diff_strategy_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_21 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_28 (TFOpLambda)        (None, 5, 2)         0           concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "                                                                 concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "wealth_20 (Subtract)            (None, 1)            0           costDot_20[0][0]                 \n",
      "                                                                 dot_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_42 (Dot)                    (None, 1)            0           absolutechanges_21[0][0]         \n",
      "                                                                 prc_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_56 (LayerNo (None, 5, 2)         4           tf.stack_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1)            0           wealth_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_21 (Lambda)                (None, 1)            0           dot_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_22 (Subtract)     (None, 1)            0           dense_22[0][0]                   \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_28 (MultiH (None, 5, 2)         14082       layer_normalization_56[0][0]     \n",
      "                                                                 layer_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "costDot_21 (Subtract)           (None, 1)            0           lambda_21[0][0]                  \n",
      "                                                                 cost_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_43 (Dot)                    (None, 1)            0           diff_strategy_21[0][0]           \n",
      "                                                                 prc_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_22 (Lambda)     (None, 1)            0           diff_strategy_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_22 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 5, 2)         0           multi_head_attention_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "wealth_21 (Subtract)            (None, 1)            0           costDot_21[0][0]                 \n",
      "                                                                 dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_44 (Dot)                    (None, 1)            0           absolutechanges_22[0][0]         \n",
      "                                                                 prc_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_28 (TFOpLa (None, 5, 2)         0           dropout_56[0][0]                 \n",
      "                                                                 tf.stack_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1)            0           wealth_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_22 (Lambda)                (None, 1)            0           dot_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_23 (Subtract)     (None, 1)            0           dense_23[0][0]                   \n",
      "                                                                 dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_57 (LayerNo (None, 5, 2)         4           tf.__operators__.add_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "costDot_22 (Subtract)           (None, 1)            0           lambda_22[0][0]                  \n",
      "                                                                 cost_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_45 (Dot)                    (None, 1)            0           diff_strategy_22[0][0]           \n",
      "                                                                 prc_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_23 (Lambda)     (None, 1)            0           diff_strategy_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_23 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 5, 5)         15          layer_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "wealth_22 (Subtract)            (None, 1)            0           costDot_22[0][0]                 \n",
      "                                                                 dot_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_46 (Dot)                    (None, 1)            0           absolutechanges_23[0][0]         \n",
      "                                                                 prc_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 5, 5)         0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1)            0           wealth_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_23 (Lambda)                (None, 1)            0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_24 (Subtract)     (None, 1)            0           dense_24[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 5, 2)         12          dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "costDot_23 (Subtract)           (None, 1)            0           lambda_23[0][0]                  \n",
      "                                                                 cost_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_47 (Dot)                    (None, 1)            0           diff_strategy_23[0][0]           \n",
      "                                                                 prc_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_24 (Lambda)     (None, 1)            0           diff_strategy_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_24 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)            (None, 10)           0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "wealth_23 (Subtract)            (None, 1)            0           costDot_23[0][0]                 \n",
      "                                                                 dot_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_48 (Dot)                    (None, 1)            0           absolutechanges_24[0][0]         \n",
      "                                                                 prc_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1)            11          reshape_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "information_set_29 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1)            0           wealth_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_24 (Lambda)                (None, 1)            0           dot_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_25 (Subtract)     (None, 1)            0           dense_25[0][0]                   \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 2)            0           information_set_29[0][0]         \n",
      "                                                                 dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "costDot_24 (Subtract)           (None, 1)            0           lambda_24[0][0]                  \n",
      "                                                                 cost_24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_49 (Dot)                    (None, 1)            0           diff_strategy_24[0][0]           \n",
      "                                                                 prc_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_25 (Lambda)     (None, 1)            0           diff_strategy_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_25 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_29 (TFOpLambda)        (None, 5, 2)         0           concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "                                                                 concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "                                                                 concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "wealth_24 (Subtract)            (None, 1)            0           costDot_24[0][0]                 \n",
      "                                                                 dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_50 (Dot)                    (None, 1)            0           absolutechanges_25[0][0]         \n",
      "                                                                 prc_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_58 (LayerNo (None, 5, 2)         4           tf.stack_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1)            0           wealth_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_25 (Lambda)                (None, 1)            0           dot_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_26 (Subtract)     (None, 1)            0           dense_26[0][0]                   \n",
      "                                                                 dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_29 (MultiH (None, 5, 2)         14082       layer_normalization_58[0][0]     \n",
      "                                                                 layer_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "costDot_25 (Subtract)           (None, 1)            0           lambda_25[0][0]                  \n",
      "                                                                 cost_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_51 (Dot)                    (None, 1)            0           diff_strategy_25[0][0]           \n",
      "                                                                 prc_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_26 (Lambda)     (None, 1)            0           diff_strategy_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_26 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 5, 2)         0           multi_head_attention_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "wealth_25 (Subtract)            (None, 1)            0           costDot_25[0][0]                 \n",
      "                                                                 dot_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_52 (Dot)                    (None, 1)            0           absolutechanges_26[0][0]         \n",
      "                                                                 prc_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_29 (TFOpLa (None, 5, 2)         0           dropout_58[0][0]                 \n",
      "                                                                 tf.stack_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1)            0           wealth_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_26 (Lambda)                (None, 1)            0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_27 (Subtract)     (None, 1)            0           dense_27[0][0]                   \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_59 (LayerNo (None, 5, 2)         4           tf.__operators__.add_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "costDot_26 (Subtract)           (None, 1)            0           lambda_26[0][0]                  \n",
      "                                                                 cost_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_53 (Dot)                    (None, 1)            0           diff_strategy_26[0][0]           \n",
      "                                                                 prc_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_27 (Lambda)     (None, 1)            0           diff_strategy_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_27 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 5, 5)         15          layer_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "wealth_26 (Subtract)            (None, 1)            0           costDot_26[0][0]                 \n",
      "                                                                 dot_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_54 (Dot)                    (None, 1)            0           absolutechanges_27[0][0]         \n",
      "                                                                 prc_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 5, 5)         0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1)            0           wealth_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_27 (Lambda)                (None, 1)            0           dot_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_28 (Subtract)     (None, 1)            0           dense_28[0][0]                   \n",
      "                                                                 dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5, 2)         12          dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "costDot_27 (Subtract)           (None, 1)            0           lambda_27[0][0]                  \n",
      "                                                                 cost_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_55 (Dot)                    (None, 1)            0           diff_strategy_27[0][0]           \n",
      "                                                                 prc_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_28 (Lambda)     (None, 1)            0           diff_strategy_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_28 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_29 (Reshape)            (None, 10)           0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "wealth_27 (Subtract)            (None, 1)            0           costDot_27[0][0]                 \n",
      "                                                                 dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_56 (Dot)                    (None, 1)            0           absolutechanges_28[0][0]         \n",
      "                                                                 prc_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1)            11          reshape_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1)            0           wealth_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_28 (Lambda)                (None, 1)            0           dot_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "diff_strategy_29 (Subtract)     (None, 1)            0           dense_29[0][0]                   \n",
      "                                                                 dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "costDot_28 (Subtract)           (None, 1)            0           lambda_28[0][0]                  \n",
      "                                                                 cost_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_57 (Dot)                    (None, 1)            0           diff_strategy_28[0][0]           \n",
      "                                                                 prc_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "absolutechanges_29 (Lambda)     (None, 1)            0           diff_strategy_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prc_29 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wealth_28 (Subtract)            (None, 1)            0           costDot_28[0][0]                 \n",
      "                                                                 dot_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_58 (Dot)                    (None, 1)            0           absolutechanges_29[0][0]         \n",
      "                                                                 prc_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1)            0           wealth_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cost_29 (Lambda)                (None, 1)            0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "costDot_29 (Subtract)           (None, 1)            0           lambda_29[0][0]                  \n",
      "                                                                 cost_29[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_59 (Dot)                    (None, 1)            0           diff_strategy_29[0][0]           \n",
      "                                                                 prc_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "wealth_29 (Subtract)            (None, 1)            0           costDot_29[0][0]                 \n",
      "                                                                 dot_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prc_30 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1)            0           wealth_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_60 (Dot)                    (None, 1)            0           dense_29[0][0]                   \n",
      "                                                                 prc_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1)            0           lambda_30[0][0]                  \n",
      "                                                                 dot_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "payoff (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wealth_30 (Add)                 (None, 1)            0           add[0][0]                        \n",
      "                                                                 payoff[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 1)            0           wealth_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 1)            0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda ()                   0           tf.math.exp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.log (TFOpLambda)        ()                   0           tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) ()                   0           tf.math.log[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf.math.multiply_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 406,902\n",
      "Trainable params: 406,902\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_recurrent.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46b1289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 12/391 [..............................] - ETA: 17:55 - loss: 16.0262"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16659/3046468499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Fit the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model_recurrent.fit(x=xtrain, batch_size=batch_size, epochs=50, \\\n\u001b[0m\u001b[1;32m     10\u001b[0m           validation_data=[xtest], verbose=1)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DL/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor=\"loss\", \\\n",
    "          patience=10, min_delta=1e-4, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", \\\n",
    "          factor=0.5, patience=2, min_delta=1e-3, verbose=0)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "# Fit the model.\n",
    "model_recurrent.fit(x=xtrain, batch_size=batch_size, epochs=50, \\\n",
    "          validation_data=[xtest], verbose=1)\n",
    "\n",
    "clear_output()\n",
    "print(\"Finished running deep hedging algorithm! (Simple Network)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title <font color='Blue'>**Results: Option Prices**</font>\n",
    "call = EuropeanCall()\n",
    "\n",
    "price_BS = call.get_BS_price(S = S_test[0], sigma = sigma, \\\n",
    "              risk_free = risk_free, dividend = dividend, K = strike, \\\n",
    "              exercise_date = maturity_date, \\\n",
    "              calculation_date = calculation_date, \\\n",
    "              day_count = day_count, dt = dt)\n",
    "delta_BS = call.get_BS_delta(S = S_test[0], sigma = sigma, \\\n",
    "              risk_free = risk_free, dividend = dividend, K = strike, \\\n",
    "              exercise_date = maturity_date, \\\n",
    "              calculation_date = calculation_date, \n",
    "              day_count = day_count, dt = dt)\n",
    "\n",
    "PnL_BS =  call.get_BS_PnL(S= S_test[0], \\\n",
    "              payoff= payoff_func(S_test[0][:,-1]), delta=delta_BS, \\\n",
    "              dt= dt, risk_free = risk_free, \\\n",
    "              final_period_cost=final_period_cost, epsilon=epsilon, \\\n",
    "              cost_structure = cost_structure )\n",
    "\n",
    "risk_neutral_price = \\\n",
    "    -option_payoff_test[0].mean()*np.exp(-risk_free*(N*dt))\n",
    "nn_simple_price = model_recurrent.evaluate(xtest, batch_size=test_size, verbose=0)\n",
    "\n",
    "print(\"The Black-Scholes model price is %2.3f.\" % price_BS[0][0])\n",
    "print(\"The Risk Neutral price is %2.3f.\" % risk_neutral_price)\n",
    "print(\"The Deep Hedging (with simple network) price is %2.3f.\" % nn_simple_price)\n",
    "\n",
    "try:\n",
    "  nn_recurrent_price = model_recurrent.evaluate(xtest, batch_size=test_size, verbose=0)\n",
    "  print(\"The Deep Hedging (with recurrent network) price is %2.3f.\" % nn_recurrent_price)\n",
    "except:\n",
    "  print(\"No Recurrent model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title <font color='Blue'>**Results: Black-Scholes PnL vs Deep Hedging PnL**</font>\n",
    "bar1 = PnL_BS + price_BS[0][0]\n",
    "bar2 = model_recurrent(xtest).numpy().squeeze() + price_BS[0][0]\n",
    "\n",
    "# Plot Black-Scholes PnL and Deep Hedging PnL (with BS_price charged on both).\n",
    "fig_PnL = plt.figure(dpi= 125, facecolor='w')\n",
    "fig_PnL.suptitle(\"Black-Scholes PnL vs Deep Hedging PnL \\n\", \\\n",
    "      fontweight=\"bold\")\n",
    "ax = fig_PnL.add_subplot()\n",
    "ax.set_title(\"Simple Network Structure with epsilon = \" + str(epsilon), \\\n",
    "      fontsize=8)\n",
    "ax.set_xlabel(\"PnL\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.hist((bar1,bar2), bins=30, \\\n",
    "          label=[\"Black-Scholes PnL\", \"Deep Hedging PnL\"])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc45eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,LSTM, Input, Lambda, Concatenate,BatchNormalization\n",
    "\n",
    "from tensorflow.keras.layers import Dot,Subtract,Add,Activation, LeakyReLU\n",
    "\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.initializers import he_normal, Zeros, he_uniform, TruncatedNormal\n",
    "\n",
    "bias_initializer=he_uniform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac24956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d = None, m = None, use_batch_norm = None, \\\n",
    "        kernel_initializer = \"he_uniform\", \\\n",
    "        activation_dense = \"relu\", activation_output = \"linear\", \n",
    "        delta_constraint = None, day = None):\n",
    "        super().__init__(name = \"delta_\" + str(day))\n",
    "        self.d = d\n",
    "        self.m = m\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.activation_dense = activation_dense\n",
    "        self.activation_output = activation_output\n",
    "        self.delta_constraint = delta_constraint\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        \n",
    "        self.intermediate_dense = [None for _ in range(d)]\n",
    "        self.intermediate_BN = [None for _ in range(d)]\n",
    "        bias_initializer=he_uniform()\n",
    "\n",
    "        for i in range(d):\n",
    "           self.intermediate_dense[i] = Dense(self.m,    \n",
    "                        kernel_initializer=self.kernel_initializer,\n",
    "                        bias_initializer=bias_initializer,\n",
    "                        use_bias=(not self.use_batch_norm))\n",
    "           if self.use_batch_norm:\n",
    "               self.intermediate_BN[i] = BatchNormalization(momentum = 0.99, trainable=True)\n",
    "           \n",
    "        self.output_dense = Dense(1, \n",
    "                      kernel_initializer=self.kernel_initializer,\n",
    "                      bias_initializer = bias_initializer,\n",
    "                      use_bias=True)     \n",
    "        \n",
    "    def call(self, input):\n",
    "        for i in range(self.d):\n",
    "            if i == 0:\n",
    "                output = self.intermediate_dense[i](input)\n",
    "            else:\n",
    "                output = self.intermediate_dense[i](output)                  \n",
    "                \n",
    "            if self.use_batch_norm:\n",
    " \t\t\t    # Batch normalization.\n",
    "                output = self.intermediate_BN[i](output, training=True)\n",
    "                \n",
    "            if self.activation_dense == \"leaky_relu\":\n",
    "                output = LeakyReLU()(output)\n",
    "            else:\n",
    "                output = Activation(self.activation_dense)(output)\n",
    "         \n",
    "        output = self.output_dense(output)\n",
    "\t\t\t\t\t \n",
    "        if self.activation_output == \"leaky_relu\":\n",
    "            output = LeakyReLU()(output)\n",
    "        elif self.activation_output == \"sigmoid\" or self.activation_output == \"tanh\" or \\\n",
    "            self.activation_output == \"hard_sigmoid\":\n",
    "            # Enforcing hedge constraints\n",
    "            if self.delta_constraint is not None:\n",
    "                output = Activation(self.activation_output)(output)\n",
    "                delta_min, delta_max = self.delta_constraint\n",
    "                output = Lambda(lambda x : (delta_max-delta_min)*x + delta_min)(output)\n",
    "            else:\n",
    "                output = Activation(self.activation_output)(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "prc = Input(shape=(1,), name = \"prc_0\")\n",
    "information_set = Input(shape=(1,), name = \"information_set_0\")\n",
    "strategy_type=\"recurrent\"\n",
    "inputs = [prc, information_set]\n",
    "past_strategy = list()\n",
    "maxT = 5\n",
    "for j in range(N+1):            \n",
    "    if j < N:\n",
    "        # Define the inputs for the strategy layers here.\n",
    "        if strategy_type == \"simple\":\n",
    "            helper1 = information_set\n",
    "        elif strategy_type == \"recurrent\":\n",
    "            if j ==0:\n",
    "                # Tensorflow hack to deal with the dimension problem.\n",
    "                #   Strategy at t = -1 should be 0. \n",
    "                # There is probably a better way but this works.\n",
    "                # Constant tensor doesn't work.\n",
    "                strategy = Lambda(lambda x: x*0.0)(prc)\n",
    "\n",
    "            past_strategy.append(strategy)\n",
    "            helper = past_strategy[-maxT:]\n",
    "            helper.append(information_set)\n",
    "            #helper1 = tf.stack(helper,axis=1)\n",
    "            helper1 = Concatenate()([information_set,strategy])\n",
    "        # Determine if the strategy function depends on time t or not.\n",
    "        if not share_stretegy_across_time:\n",
    "            strategy_layer = Strategy_Layer(d = d, m = m, \n",
    "                         use_batch_norm = use_batch_norm, \\\n",
    "                         kernel_initializer = kernel_initializer, \\\n",
    "                         activation_dense = activation_dense, \\\n",
    "                         activation_output = activation_output, \n",
    "                         delta_constraint = delta_constraint, \\\n",
    "                         day = j)\n",
    "\n",
    "            strategyhelper = strategy_layer(helper1)\n",
    "\n",
    "        else:\n",
    "            if j == 0:\n",
    "                strategyhelper1 = LSTM(m,return_sequences=False,\n",
    "                                      kernel_initializer=kernel_initializer,\n",
    "                        bias_initializer=he_uniform())(helper1,training=True)\n",
    "                strategyhelper = Dense(1,kernel_initializer=kernel_initializer,\n",
    "                        bias_initializer=he_uniform())(strategyhelper1,training=True)\n",
    "\n",
    "                strategyhelper = BatchNormalization(momentum = 0.99,\n",
    "                                trainable=True)(strategyhelper,training=True)\n",
    "        # strategy_-1 is set to 0\n",
    "        # delta_strategy = strategy_{t+1} - strategy_t\n",
    "        if j == 0:              \n",
    "            delta_strategy = strategyhelper\n",
    "        else:\n",
    "            delta_strategy = Subtract(name = \"diff_strategy_\" + str(j))([strategyhelper, strategy])\n",
    "\n",
    "        if cost_structure == \"proportional\": \n",
    "            # Proportional transaction cost\n",
    "            absolutechanges = Lambda(lambda x : K.abs(x), name = \"absolutechanges_\" + str(j))(delta_strategy)\n",
    "            costs = Dot(axes=1)([absolutechanges,prc])\n",
    "            costs = Lambda(lambda x : epsilon*x, name = \"cost_\" + str(j))(costs)\n",
    "        elif cost_structure == \"constant\":\n",
    "            # Tensorflow hack..\n",
    "            costs = Lambda(lambda x : epsilon + x*0.0)(prc)\n",
    "\n",
    "        if j == 0:\n",
    "            wealth = Lambda(lambda x : initial_wealth - x, name = \"costDot_\" + str(j))(costs)\n",
    "        else:\n",
    "            wealth = Subtract(name = \"costDot_\" + str(j))([wealth, costs])\n",
    "\n",
    "        # Wealth for the next period\n",
    "        # w_{t+1} = w_t + (strategy_t-strategy_{t+1})*prc_t\n",
    "        #         = w_t - delta_strategy*prc_t\n",
    "        mult = Dot(axes=1)([delta_strategy, prc])\n",
    "        wealth = Subtract(name = \"wealth_\" + str(j))([wealth, mult])\n",
    "\n",
    "        # Accumulate interest rate for next period.\n",
    "        FV_factor = np.exp(risk_free*dt)\n",
    "        wealth = Lambda(lambda x: x*FV_factor)(wealth)\n",
    "\n",
    "        prc = Input(shape=(1,),name = \"prc_\" + str(j+1))\n",
    "        information_set = Input(shape=(1,), name = \"information_set_\" + str(j+1))\n",
    "\n",
    "        strategy = strategyhelper    \n",
    "\n",
    "        if j != N - 1:\n",
    "            inputs += [prc, information_set]\n",
    "        else:\n",
    "            inputs += [prc]\n",
    "    else:\n",
    "        # The paper assumes no transaction costs for the final period \n",
    "        # when the position is liquidated.\n",
    "        if final_period_cost:\n",
    "            if cost_structure == \"proportional\":\n",
    "                # Proportional transaction cost\n",
    "                absolutechanges = Lambda(lambda x : K.abs(x), name = \"absolutechanges_\" + str(j))(strategy)\n",
    "                costs = Dot(axes=1)([absolutechanges,prc])\n",
    "                costs = Lambda(lambda x : epsilon*x, name = \"cost_\" + str(j))(costs)\n",
    "            elif cost_structure == \"constant\":\n",
    "                # Tensorflow hack..\n",
    "                costs = Lambda(lambda x : epsilon + x*0.0)(prc)\n",
    "\n",
    "            wealth = Subtract(name = \"costDot_\" + str(j))([wealth, costs])\n",
    "        # Wealth for the final period\n",
    "        # -delta_strategy = strategy_t\n",
    "        mult = Dot(axes=1)([strategy, prc])\n",
    "        wealth = Add()([wealth, mult])\n",
    "\n",
    "        # Add the terminal payoff of any derivatives.\n",
    "        payoff = Input(shape=(1,), name = \"payoff\")\n",
    "        inputs += [payoff]\n",
    "\n",
    "        wealth = Add(name = \"wealth_\" + str(j))([wealth,payoff])\n",
    "        model = Model(inputs=inputs, outputs=wealth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d0e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ca793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy_loss(wealth=None, w=None, loss_param=None):\n",
    "    _lambda = loss_param\n",
    "\n",
    "    return (1/_lambda)*K.log(K.mean(K.exp(-_lambda*wealth)))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=lr),loss=Entropy_loss)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f5284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866962ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
